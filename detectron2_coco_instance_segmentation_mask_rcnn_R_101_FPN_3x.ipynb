{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a86232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8\n",
      "Detectron2 is working!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "print(torch.version.cuda)\n",
    "setup_logger()\n",
    "print(\"Detectron2 is working!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf217f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# Unregister the dataset if it's already registered\n",
    "for d in [\"food_train\", \"food_val\"]:\n",
    "    if d in DatasetCatalog.list():\n",
    "        DatasetCatalog.remove(d)\n",
    "        MetadataCatalog.remove(d)\n",
    "\n",
    "# Now register again with correct paths\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(\"food_train\", {}, r\"dataset/annotation/train_annotation.json\", \"dataset/train\")\n",
    "register_coco_instances(\"food_val\", {}, r\"dataset/annotation/valid_annotations.json\", \"dataset/valid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035adedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "import os\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))  # change here\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
    "cfg.DATASETS.TRAIN = (\"food_train\",)\n",
    "cfg.DATASETS.TEST = (\"food_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 3000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 15  # your number of food classes\n",
    "\n",
    "cfg.OUTPUT_DIR = \"./output_R101\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e1f47cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/14 09:42:31 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=16, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=60, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[05/14 09:42:31 d2.data.datasets.coco]: \u001b[0mLoaded 1200 images in COCO format from dataset/annotation/train_annotation.json\n",
      "\u001b[32m[05/14 09:42:31 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1200 images left.\n",
      "\u001b[32m[05/14 09:42:32 d2.data.build]: \u001b[0mDistribution of instances among all 15 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Whole Chicken | 81           | Chicken Bre.. | 202          | Chicken Wings | 399          |\n",
      "|  Chicken Leg  | 395          | Chicken Thigh | 366          |      Egg      | 177          |\n",
      "|     Tofu      | 120          |   Lean Pork   | 216          |   Lean Beef   | 89           |\n",
      "| Sweet Potato  | 256          |   Potatoes    | 97           |     Rice      | 83           |\n",
      "| Whole Wheat.. | 192          |  White Bread  | 227          |   Broccolli   | 162          |\n",
      "|               |              |               |              |               |              |\n",
      "|     total     | 3062         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[05/14 09:42:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[05/14 09:42:32 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[05/14 09:42:32 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[05/14 09:42:32 d2.data.common]: \u001b[0mSerializing 1200 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/14 09:42:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.40 MiB\n",
      "\u001b[32m[05/14 09:42:32 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/14 09:42:32 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[05/14 09:42:32 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x/138205316/model_final_a3ec72.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_a3ec72.pkl: 254MB [00:10, 24.0MB/s]                              \n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (60, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (60,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (15, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/14 09:42:43 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\Desktop\\Thesis\\foodenv312\\Lib\\site-packages\\torch\\functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4316.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/14 09:42:58 d2.utils.events]: \u001b[0m eta: 0:18:37  iter: 19  total_loss: 4.143  loss_cls: 2.744  loss_box_reg: 0.6613  loss_mask: 0.6933  loss_rpn_cls: 0.012  loss_rpn_loc: 0.01149    time: 0.3724  last_time: 0.3099  data_time: 0.2764  last_data_time: 0.0016   lr: 4.9953e-06  max_mem: 2254M\n",
      "\u001b[32m[05/14 09:43:06 d2.utils.events]: \u001b[0m eta: 0:18:38  iter: 39  total_loss: 3.889  loss_cls: 2.591  loss_box_reg: 0.5992  loss_mask: 0.6944  loss_rpn_cls: 0.009766  loss_rpn_loc: 0.009509    time: 0.3791  last_time: 0.3348  data_time: 0.0013  last_data_time: 0.0011   lr: 9.9902e-06  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:43:14 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 59  total_loss: 3.728  loss_cls: 2.308  loss_box_reg: 0.6941  loss_mask: 0.6895  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.01469    time: 0.3709  last_time: 0.3607  data_time: 0.0012  last_data_time: 0.0012   lr: 1.4985e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:43:21 d2.utils.events]: \u001b[0m eta: 0:17:50  iter: 79  total_loss: 3.194  loss_cls: 1.795  loss_box_reg: 0.6458  loss_mask: 0.6855  loss_rpn_cls: 0.005722  loss_rpn_loc: 0.01001    time: 0.3657  last_time: 0.3582  data_time: 0.0012  last_data_time: 0.0011   lr: 1.998e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:43:28 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 99  total_loss: 2.56  loss_cls: 1.263  loss_box_reg: 0.577  loss_mask: 0.6836  loss_rpn_cls: 0.008743  loss_rpn_loc: 0.01058    time: 0.3657  last_time: 0.3696  data_time: 0.0012  last_data_time: 0.0012   lr: 2.4975e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:43:35 d2.utils.events]: \u001b[0m eta: 0:17:39  iter: 119  total_loss: 2.475  loss_cls: 1  loss_box_reg: 0.7683  loss_mask: 0.6782  loss_rpn_cls: 0.009264  loss_rpn_loc: 0.01339    time: 0.3645  last_time: 0.3886  data_time: 0.0013  last_data_time: 0.0012   lr: 2.997e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:43:42 d2.utils.events]: \u001b[0m eta: 0:17:32  iter: 139  total_loss: 2.151  loss_cls: 0.7744  loss_box_reg: 0.6806  loss_mask: 0.6665  loss_rpn_cls: 0.003598  loss_rpn_loc: 0.01198    time: 0.3636  last_time: 0.3118  data_time: 0.0012  last_data_time: 0.0009   lr: 3.4965e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:43:50 d2.utils.events]: \u001b[0m eta: 0:17:36  iter: 159  total_loss: 2.28  loss_cls: 0.8486  loss_box_reg: 0.714  loss_mask: 0.6664  loss_rpn_cls: 0.00417  loss_rpn_loc: 0.01285    time: 0.3671  last_time: 0.3702  data_time: 0.0014  last_data_time: 0.0010   lr: 3.996e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:43:57 d2.utils.events]: \u001b[0m eta: 0:17:29  iter: 179  total_loss: 2.015  loss_cls: 0.7041  loss_box_reg: 0.6502  loss_mask: 0.6514  loss_rpn_cls: 0.004182  loss_rpn_loc: 0.009414    time: 0.3670  last_time: 0.3321  data_time: 0.0013  last_data_time: 0.0011   lr: 4.4955e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:44:05 d2.utils.events]: \u001b[0m eta: 0:17:22  iter: 199  total_loss: 1.966  loss_cls: 0.6837  loss_box_reg: 0.6151  loss_mask: 0.6318  loss_rpn_cls: 0.00363  loss_rpn_loc: 0.008442    time: 0.3676  last_time: 0.3512  data_time: 0.0013  last_data_time: 0.0010   lr: 4.995e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:44:12 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 219  total_loss: 2.186  loss_cls: 0.802  loss_box_reg: 0.7439  loss_mask: 0.6298  loss_rpn_cls: 0.003554  loss_rpn_loc: 0.01334    time: 0.3677  last_time: 0.3478  data_time: 0.0013  last_data_time: 0.0013   lr: 5.4945e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:44:20 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 239  total_loss: 2.06  loss_cls: 0.722  loss_box_reg: 0.6999  loss_mask: 0.6188  loss_rpn_cls: 0.00531  loss_rpn_loc: 0.009752    time: 0.3686  last_time: 0.3738  data_time: 0.0015  last_data_time: 0.0012   lr: 5.994e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:44:27 d2.utils.events]: \u001b[0m eta: 0:17:00  iter: 259  total_loss: 1.93  loss_cls: 0.6268  loss_box_reg: 0.6793  loss_mask: 0.602  loss_rpn_cls: 0.008069  loss_rpn_loc: 0.009568    time: 0.3671  last_time: 0.2787  data_time: 0.0012  last_data_time: 0.0012   lr: 6.4935e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:44:34 d2.utils.events]: \u001b[0m eta: 0:16:51  iter: 279  total_loss: 1.983  loss_cls: 0.6591  loss_box_reg: 0.6648  loss_mask: 0.584  loss_rpn_cls: 0.003627  loss_rpn_loc: 0.01201    time: 0.3666  last_time: 0.3416  data_time: 0.0012  last_data_time: 0.0009   lr: 6.993e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:44:41 d2.utils.events]: \u001b[0m eta: 0:16:39  iter: 299  total_loss: 2.049  loss_cls: 0.7011  loss_box_reg: 0.7372  loss_mask: 0.5431  loss_rpn_cls: 0.005974  loss_rpn_loc: 0.008775    time: 0.3661  last_time: 0.3318  data_time: 0.0012  last_data_time: 0.0013   lr: 7.4925e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:44:48 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 319  total_loss: 1.908  loss_cls: 0.6644  loss_box_reg: 0.683  loss_mask: 0.5353  loss_rpn_cls: 0.001871  loss_rpn_loc: 0.009574    time: 0.3656  last_time: 0.3631  data_time: 0.0012  last_data_time: 0.0013   lr: 7.992e-05  max_mem: 2310M\n",
      "\u001b[32m[05/14 09:44:56 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 339  total_loss: 1.872  loss_cls: 0.6219  loss_box_reg: 0.6936  loss_mask: 0.5434  loss_rpn_cls: 0.006016  loss_rpn_loc: 0.006689    time: 0.3655  last_time: 0.3890  data_time: 0.0012  last_data_time: 0.0012   lr: 8.4915e-05  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:45:03 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 359  total_loss: 1.931  loss_cls: 0.7086  loss_box_reg: 0.7513  loss_mask: 0.4899  loss_rpn_cls: 0.005766  loss_rpn_loc: 0.0132    time: 0.3666  last_time: 0.3817  data_time: 0.0013  last_data_time: 0.0011   lr: 8.991e-05  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:45:11 d2.utils.events]: \u001b[0m eta: 0:16:11  iter: 379  total_loss: 1.785  loss_cls: 0.6247  loss_box_reg: 0.6951  loss_mask: 0.4548  loss_rpn_cls: 0.006618  loss_rpn_loc: 0.008038    time: 0.3660  last_time: 0.3295  data_time: 0.0012  last_data_time: 0.0010   lr: 9.4905e-05  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:45:18 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 399  total_loss: 1.901  loss_cls: 0.6933  loss_box_reg: 0.6914  loss_mask: 0.4737  loss_rpn_cls: 0.007229  loss_rpn_loc: 0.01172    time: 0.3656  last_time: 0.3281  data_time: 0.0011  last_data_time: 0.0009   lr: 9.99e-05  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:45:25 d2.utils.events]: \u001b[0m eta: 0:15:54  iter: 419  total_loss: 1.853  loss_cls: 0.6936  loss_box_reg: 0.6994  loss_mask: 0.4544  loss_rpn_cls: 0.009043  loss_rpn_loc: 0.01602    time: 0.3652  last_time: 0.3921  data_time: 0.0012  last_data_time: 0.0013   lr: 0.0001049  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:45:32 d2.utils.events]: \u001b[0m eta: 0:15:43  iter: 439  total_loss: 1.768  loss_cls: 0.6312  loss_box_reg: 0.7021  loss_mask: 0.3965  loss_rpn_cls: 0.004477  loss_rpn_loc: 0.01108    time: 0.3645  last_time: 0.3720  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00010989  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:45:39 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 459  total_loss: 1.577  loss_cls: 0.5987  loss_box_reg: 0.651  loss_mask: 0.3985  loss_rpn_cls: 0.003547  loss_rpn_loc: 0.011    time: 0.3645  last_time: 0.3823  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00011489  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:45:47 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 479  total_loss: 1.547  loss_cls: 0.5559  loss_box_reg: 0.5958  loss_mask: 0.3765  loss_rpn_cls: 0.00448  loss_rpn_loc: 0.007731    time: 0.3647  last_time: 0.4037  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00011988  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:45:54 d2.utils.events]: \u001b[0m eta: 0:15:24  iter: 499  total_loss: 1.753  loss_cls: 0.6277  loss_box_reg: 0.6584  loss_mask: 0.3971  loss_rpn_cls: 0.003304  loss_rpn_loc: 0.01002    time: 0.3649  last_time: 0.3933  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00012488  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:46:01 d2.utils.events]: \u001b[0m eta: 0:15:18  iter: 519  total_loss: 1.754  loss_cls: 0.6815  loss_box_reg: 0.7186  loss_mask: 0.3372  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.01145    time: 0.3651  last_time: 0.3802  data_time: 0.0014  last_data_time: 0.0011   lr: 0.00012987  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:46:09 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 539  total_loss: 1.634  loss_cls: 0.6148  loss_box_reg: 0.6798  loss_mask: 0.3  loss_rpn_cls: 0.006552  loss_rpn_loc: 0.00844    time: 0.3659  last_time: 0.4256  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00013487  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:46:16 d2.utils.events]: \u001b[0m eta: 0:15:06  iter: 559  total_loss: 1.616  loss_cls: 0.617  loss_box_reg: 0.6735  loss_mask: 0.2755  loss_rpn_cls: 0.0008427  loss_rpn_loc: 0.00903    time: 0.3658  last_time: 0.3654  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00013986  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:46:24 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 579  total_loss: 1.585  loss_cls: 0.5948  loss_box_reg: 0.6683  loss_mask: 0.2479  loss_rpn_cls: 0.001701  loss_rpn_loc: 0.00951    time: 0.3669  last_time: 0.3970  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00014486  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:46:32 d2.utils.events]: \u001b[0m eta: 0:14:53  iter: 599  total_loss: 1.387  loss_cls: 0.5577  loss_box_reg: 0.5999  loss_mask: 0.27  loss_rpn_cls: 0.006856  loss_rpn_loc: 0.01031    time: 0.3674  last_time: 0.3751  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00014985  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:46:40 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 619  total_loss: 1.48  loss_cls: 0.5354  loss_box_reg: 0.6677  loss_mask: 0.2277  loss_rpn_cls: 0.0007064  loss_rpn_loc: 0.0103    time: 0.3677  last_time: 0.4153  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00015485  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:46:47 d2.utils.events]: \u001b[0m eta: 0:14:39  iter: 639  total_loss: 1.315  loss_cls: 0.4584  loss_box_reg: 0.5784  loss_mask: 0.2161  loss_rpn_cls: 0.001182  loss_rpn_loc: 0.01568    time: 0.3680  last_time: 0.3860  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00015984  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:46:55 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 659  total_loss: 1.371  loss_cls: 0.6021  loss_box_reg: 0.5508  loss_mask: 0.1863  loss_rpn_cls: 0.005053  loss_rpn_loc: 0.008734    time: 0.3690  last_time: 0.4183  data_time: 0.0013  last_data_time: 0.0019   lr: 0.00016484  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:47:03 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 679  total_loss: 1.32  loss_cls: 0.5265  loss_box_reg: 0.5302  loss_mask: 0.2154  loss_rpn_cls: 0.005549  loss_rpn_loc: 0.01488    time: 0.3697  last_time: 0.3622  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00016983  max_mem: 2313M\n",
      "\u001b[32m[05/14 09:47:11 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 699  total_loss: 1.394  loss_cls: 0.6161  loss_box_reg: 0.4677  loss_mask: 0.2065  loss_rpn_cls: 0.001616  loss_rpn_loc: 0.01513    time: 0.3698  last_time: 0.3884  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00017483  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:47:18 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 719  total_loss: 1.365  loss_cls: 0.5187  loss_box_reg: 0.5025  loss_mask: 0.2276  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.01663    time: 0.3701  last_time: 0.3209  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00017982  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:47:26 d2.utils.events]: \u001b[0m eta: 0:14:03  iter: 739  total_loss: 1.03  loss_cls: 0.4682  loss_box_reg: 0.4348  loss_mask: 0.169  loss_rpn_cls: 0.0008779  loss_rpn_loc: 0.008974    time: 0.3703  last_time: 0.3560  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00018482  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:47:33 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 759  total_loss: 1.157  loss_cls: 0.5455  loss_box_reg: 0.4343  loss_mask: 0.2064  loss_rpn_cls: 0.003642  loss_rpn_loc: 0.01103    time: 0.3706  last_time: 0.4161  data_time: 0.0013  last_data_time: 0.0009   lr: 0.00018981  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:47:41 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 779  total_loss: 1.077  loss_cls: 0.4088  loss_box_reg: 0.3963  loss_mask: 0.1843  loss_rpn_cls: 0.001888  loss_rpn_loc: 0.006789    time: 0.3710  last_time: 0.4073  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00019481  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:47:49 d2.utils.events]: \u001b[0m eta: 0:13:43  iter: 799  total_loss: 1.311  loss_cls: 0.5458  loss_box_reg: 0.4401  loss_mask: 0.2554  loss_rpn_cls: 0.002143  loss_rpn_loc: 0.01226    time: 0.3711  last_time: 0.4155  data_time: 0.0012  last_data_time: 0.0011   lr: 0.0001998  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:47:56 d2.utils.events]: \u001b[0m eta: 0:13:37  iter: 819  total_loss: 1.204  loss_cls: 0.5155  loss_box_reg: 0.4025  loss_mask: 0.2214  loss_rpn_cls: 0.008137  loss_rpn_loc: 0.01195    time: 0.3714  last_time: 0.3910  data_time: 0.0012  last_data_time: 0.0009   lr: 0.0002048  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:48:04 d2.utils.events]: \u001b[0m eta: 0:13:30  iter: 839  total_loss: 1.147  loss_cls: 0.5066  loss_box_reg: 0.3869  loss_mask: 0.2013  loss_rpn_cls: 0.00352  loss_rpn_loc: 0.008221    time: 0.3717  last_time: 0.3887  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00020979  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:48:12 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 859  total_loss: 1.152  loss_cls: 0.4327  loss_box_reg: 0.4545  loss_mask: 0.2052  loss_rpn_cls: 0.00118  loss_rpn_loc: 0.01124    time: 0.3720  last_time: 0.3608  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00021479  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:48:19 d2.utils.events]: \u001b[0m eta: 0:13:16  iter: 879  total_loss: 1.068  loss_cls: 0.463  loss_box_reg: 0.4168  loss_mask: 0.1851  loss_rpn_cls: 0.004802  loss_rpn_loc: 0.0111    time: 0.3721  last_time: 0.3642  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00021978  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:48:27 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 899  total_loss: 0.9507  loss_cls: 0.4023  loss_box_reg: 0.327  loss_mask: 0.1982  loss_rpn_cls: 0.001935  loss_rpn_loc: 0.009997    time: 0.3726  last_time: 0.3819  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00022478  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:48:35 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 919  total_loss: 0.89  loss_cls: 0.3671  loss_box_reg: 0.3257  loss_mask: 0.1918  loss_rpn_cls: 0.005462  loss_rpn_loc: 0.008254    time: 0.3730  last_time: 0.4103  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00022977  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:48:42 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 939  total_loss: 1.008  loss_cls: 0.5007  loss_box_reg: 0.3534  loss_mask: 0.187  loss_rpn_cls: 0.003376  loss_rpn_loc: 0.01335    time: 0.3731  last_time: 0.3487  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00023477  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:48:50 d2.utils.events]: \u001b[0m eta: 0:12:49  iter: 959  total_loss: 1.003  loss_cls: 0.4567  loss_box_reg: 0.3628  loss_mask: 0.2038  loss_rpn_cls: 0.0007692  loss_rpn_loc: 0.009949    time: 0.3733  last_time: 0.4197  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00023976  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:48:58 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 979  total_loss: 0.8613  loss_cls: 0.3023  loss_box_reg: 0.3279  loss_mask: 0.204  loss_rpn_cls: 0.0006694  loss_rpn_loc: 0.01019    time: 0.3734  last_time: 0.3161  data_time: 0.0011  last_data_time: 0.0009   lr: 0.00024476  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:49:05 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 999  total_loss: 0.9626  loss_cls: 0.4197  loss_box_reg: 0.3674  loss_mask: 0.1795  loss_rpn_cls: 0.003161  loss_rpn_loc: 0.01077    time: 0.3736  last_time: 0.4269  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00024975  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:49:13 d2.utils.events]: \u001b[0m eta: 0:12:27  iter: 1019  total_loss: 1.124  loss_cls: 0.4126  loss_box_reg: 0.3689  loss_mask: 0.229  loss_rpn_cls: 0.007099  loss_rpn_loc: 0.01062    time: 0.3735  last_time: 0.3821  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:49:20 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 1039  total_loss: 1.046  loss_cls: 0.4281  loss_box_reg: 0.385  loss_mask: 0.1817  loss_rpn_cls: 0.003168  loss_rpn_loc: 0.01323    time: 0.3737  last_time: 0.3575  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:49:28 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 1059  total_loss: 0.8665  loss_cls: 0.3993  loss_box_reg: 0.3018  loss_mask: 0.1926  loss_rpn_cls: 0.002456  loss_rpn_loc: 0.009162    time: 0.3739  last_time: 0.3994  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:49:36 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 1079  total_loss: 0.9529  loss_cls: 0.382  loss_box_reg: 0.3272  loss_mask: 0.1918  loss_rpn_cls: 0.002833  loss_rpn_loc: 0.008211    time: 0.3739  last_time: 0.3507  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:49:44 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 1099  total_loss: 0.8691  loss_cls: 0.3136  loss_box_reg: 0.3613  loss_mask: 0.2085  loss_rpn_cls: 0.0002033  loss_rpn_loc: 0.008115    time: 0.3744  last_time: 0.3789  data_time: 0.0013  last_data_time: 0.0017   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:49:51 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 1119  total_loss: 0.8763  loss_cls: 0.3966  loss_box_reg: 0.3026  loss_mask: 0.1785  loss_rpn_cls: 0.0008909  loss_rpn_loc: 0.0075    time: 0.3746  last_time: 0.3906  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:49:59 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 1139  total_loss: 0.8365  loss_cls: 0.3654  loss_box_reg: 0.2924  loss_mask: 0.1566  loss_rpn_cls: 0.000528  loss_rpn_loc: 0.005628    time: 0.3747  last_time: 0.3821  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:50:07 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 1159  total_loss: 0.9081  loss_cls: 0.3589  loss_box_reg: 0.2685  loss_mask: 0.201  loss_rpn_cls: 0.003189  loss_rpn_loc: 0.01073    time: 0.3749  last_time: 0.3892  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:50:15 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 1179  total_loss: 0.8631  loss_cls: 0.2679  loss_box_reg: 0.2946  loss_mask: 0.1797  loss_rpn_cls: 0.001548  loss_rpn_loc: 0.007484    time: 0.3753  last_time: 0.4030  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:50:22 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 1199  total_loss: 0.8341  loss_cls: 0.3276  loss_box_reg: 0.3303  loss_mask: 0.1705  loss_rpn_cls: 0.001848  loss_rpn_loc: 0.0118    time: 0.3755  last_time: 0.3836  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:50:30 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 1219  total_loss: 0.793  loss_cls: 0.2434  loss_box_reg: 0.3129  loss_mask: 0.19  loss_rpn_cls: 0.002732  loss_rpn_loc: 0.01149    time: 0.3755  last_time: 0.3841  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:50:38 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 1239  total_loss: 0.9634  loss_cls: 0.355  loss_box_reg: 0.336  loss_mask: 0.1769  loss_rpn_cls: 0.001815  loss_rpn_loc: 0.01153    time: 0.3758  last_time: 0.3766  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:50:46 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 1259  total_loss: 0.8928  loss_cls: 0.3399  loss_box_reg: 0.3571  loss_mask: 0.1826  loss_rpn_cls: 0.003184  loss_rpn_loc: 0.007978    time: 0.3761  last_time: 0.4218  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:50:53 d2.utils.events]: \u001b[0m eta: 0:10:58  iter: 1279  total_loss: 0.8296  loss_cls: 0.3202  loss_box_reg: 0.277  loss_mask: 0.1957  loss_rpn_cls: 0.0008807  loss_rpn_loc: 0.007994    time: 0.3761  last_time: 0.3881  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:51:01 d2.utils.events]: \u001b[0m eta: 0:10:52  iter: 1299  total_loss: 0.868  loss_cls: 0.3411  loss_box_reg: 0.2991  loss_mask: 0.1882  loss_rpn_cls: 0.0002733  loss_rpn_loc: 0.008651    time: 0.3761  last_time: 0.3891  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:51:09 d2.utils.events]: \u001b[0m eta: 0:10:44  iter: 1319  total_loss: 0.6912  loss_cls: 0.2828  loss_box_reg: 0.2208  loss_mask: 0.1555  loss_rpn_cls: 0.002036  loss_rpn_loc: 0.00855    time: 0.3762  last_time: 0.3151  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:51:16 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 1339  total_loss: 0.765  loss_cls: 0.271  loss_box_reg: 0.306  loss_mask: 0.1819  loss_rpn_cls: 0.002839  loss_rpn_loc: 0.006696    time: 0.3764  last_time: 0.3341  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:51:24 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 1359  total_loss: 0.7297  loss_cls: 0.3111  loss_box_reg: 0.3098  loss_mask: 0.1717  loss_rpn_cls: 0.001026  loss_rpn_loc: 0.007184    time: 0.3766  last_time: 0.3743  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:51:32 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 1379  total_loss: 0.7345  loss_cls: 0.2495  loss_box_reg: 0.2704  loss_mask: 0.1651  loss_rpn_cls: 0.0005244  loss_rpn_loc: 0.0078    time: 0.3771  last_time: 0.3480  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:51:40 d2.utils.events]: \u001b[0m eta: 0:10:19  iter: 1399  total_loss: 0.7528  loss_cls: 0.2816  loss_box_reg: 0.2557  loss_mask: 0.1347  loss_rpn_cls: 0.001983  loss_rpn_loc: 0.006543    time: 0.3775  last_time: 0.3676  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:51:48 d2.utils.events]: \u001b[0m eta: 0:10:11  iter: 1419  total_loss: 0.7681  loss_cls: 0.3042  loss_box_reg: 0.2645  loss_mask: 0.1562  loss_rpn_cls: 0.00295  loss_rpn_loc: 0.008549    time: 0.3775  last_time: 0.3312  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:51:56 d2.utils.events]: \u001b[0m eta: 0:10:04  iter: 1439  total_loss: 0.7044  loss_cls: 0.3049  loss_box_reg: 0.2559  loss_mask: 0.1498  loss_rpn_cls: 0.001284  loss_rpn_loc: 0.006831    time: 0.3776  last_time: 0.4262  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:52:04 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 1459  total_loss: 0.7787  loss_cls: 0.3221  loss_box_reg: 0.2549  loss_mask: 0.1734  loss_rpn_cls: 0.004299  loss_rpn_loc: 0.01285    time: 0.3778  last_time: 0.4202  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:52:11 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 1479  total_loss: 0.8586  loss_cls: 0.3596  loss_box_reg: 0.2536  loss_mask: 0.1844  loss_rpn_cls: 0.00131  loss_rpn_loc: 0.01087    time: 0.3779  last_time: 0.3937  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:52:19 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 1499  total_loss: 0.6925  loss_cls: 0.2729  loss_box_reg: 0.2252  loss_mask: 0.1606  loss_rpn_cls: 0.001444  loss_rpn_loc: 0.007759    time: 0.3780  last_time: 0.4245  data_time: 0.0012  last_data_time: 0.0017   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:52:27 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 1519  total_loss: 0.7807  loss_cls: 0.3007  loss_box_reg: 0.2453  loss_mask: 0.1756  loss_rpn_cls: 0.0006754  loss_rpn_loc: 0.009705    time: 0.3781  last_time: 0.3920  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:52:34 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 1539  total_loss: 0.8731  loss_cls: 0.3337  loss_box_reg: 0.3165  loss_mask: 0.196  loss_rpn_cls: 0.0008321  loss_rpn_loc: 0.008234    time: 0.3782  last_time: 0.3648  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:52:42 d2.utils.events]: \u001b[0m eta: 0:09:19  iter: 1559  total_loss: 0.8579  loss_cls: 0.242  loss_box_reg: 0.3473  loss_mask: 0.2049  loss_rpn_cls: 0.001688  loss_rpn_loc: 0.008137    time: 0.3782  last_time: 0.3278  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:52:50 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 1579  total_loss: 0.5029  loss_cls: 0.2133  loss_box_reg: 0.2049  loss_mask: 0.1288  loss_rpn_cls: 0.002131  loss_rpn_loc: 0.009872    time: 0.3782  last_time: 0.3521  data_time: 0.0013  last_data_time: 0.0009   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:52:58 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 1599  total_loss: 0.7478  loss_cls: 0.3065  loss_box_reg: 0.2415  loss_mask: 0.1528  loss_rpn_cls: 0.003573  loss_rpn_loc: 0.01031    time: 0.3784  last_time: 0.4097  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:53:05 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 1619  total_loss: 0.6275  loss_cls: 0.2382  loss_box_reg: 0.1971  loss_mask: 0.1397  loss_rpn_cls: 0.001189  loss_rpn_loc: 0.005636    time: 0.3786  last_time: 0.3949  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:53:13 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 1639  total_loss: 0.7227  loss_cls: 0.3095  loss_box_reg: 0.2589  loss_mask: 0.1777  loss_rpn_cls: 0.002414  loss_rpn_loc: 0.01432    time: 0.3787  last_time: 0.4213  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:53:21 d2.utils.events]: \u001b[0m eta: 0:08:40  iter: 1659  total_loss: 0.8256  loss_cls: 0.3092  loss_box_reg: 0.2727  loss_mask: 0.1753  loss_rpn_cls: 0.002505  loss_rpn_loc: 0.007923    time: 0.3789  last_time: 0.4321  data_time: 0.0013  last_data_time: 0.0018   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:53:29 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 1679  total_loss: 0.7376  loss_cls: 0.3074  loss_box_reg: 0.2189  loss_mask: 0.1612  loss_rpn_cls: 0.00342  loss_rpn_loc: 0.01145    time: 0.3794  last_time: 0.3398  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:53:37 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 1699  total_loss: 0.6238  loss_cls: 0.2211  loss_box_reg: 0.2467  loss_mask: 0.1555  loss_rpn_cls: 0.002775  loss_rpn_loc: 0.00825    time: 0.3796  last_time: 0.3747  data_time: 0.0014  last_data_time: 0.0017   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:53:46 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 1719  total_loss: 0.8681  loss_cls: 0.3638  loss_box_reg: 0.296  loss_mask: 0.2036  loss_rpn_cls: 0.0007715  loss_rpn_loc: 0.008299    time: 0.3801  last_time: 0.4035  data_time: 0.0015  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:53:54 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 1739  total_loss: 0.8884  loss_cls: 0.3321  loss_box_reg: 0.2579  loss_mask: 0.1996  loss_rpn_cls: 0.002219  loss_rpn_loc: 0.01185    time: 0.3804  last_time: 0.4265  data_time: 0.0015  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:54:02 d2.utils.events]: \u001b[0m eta: 0:08:04  iter: 1759  total_loss: 0.7214  loss_cls: 0.2921  loss_box_reg: 0.2644  loss_mask: 0.1855  loss_rpn_cls: 0.003125  loss_rpn_loc: 0.008058    time: 0.3805  last_time: 0.3651  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:54:10 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 1779  total_loss: 0.7402  loss_cls: 0.2195  loss_box_reg: 0.302  loss_mask: 0.1819  loss_rpn_cls: 0.0001546  loss_rpn_loc: 0.008644    time: 0.3806  last_time: 0.3897  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:54:17 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 1799  total_loss: 0.7144  loss_cls: 0.2583  loss_box_reg: 0.2561  loss_mask: 0.1828  loss_rpn_cls: 0.002368  loss_rpn_loc: 0.00788    time: 0.3808  last_time: 0.3900  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:54:25 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 1819  total_loss: 0.7276  loss_cls: 0.2213  loss_box_reg: 0.2449  loss_mask: 0.2128  loss_rpn_cls: 0.003678  loss_rpn_loc: 0.012    time: 0.3810  last_time: 0.4201  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:54:33 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 1839  total_loss: 0.7789  loss_cls: 0.2781  loss_box_reg: 0.2875  loss_mask: 0.1867  loss_rpn_cls: 0.002832  loss_rpn_loc: 0.009655    time: 0.3810  last_time: 0.3539  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:54:41 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 1859  total_loss: 0.6126  loss_cls: 0.2071  loss_box_reg: 0.2173  loss_mask: 0.1519  loss_rpn_cls: 0.001616  loss_rpn_loc: 0.00832    time: 0.3810  last_time: 0.4028  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:54:48 d2.utils.events]: \u001b[0m eta: 0:07:17  iter: 1879  total_loss: 0.5974  loss_cls: 0.2444  loss_box_reg: 0.2159  loss_mask: 0.1421  loss_rpn_cls: 0.0009842  loss_rpn_loc: 0.006461    time: 0.3810  last_time: 0.3534  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:54:56 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 1899  total_loss: 0.6804  loss_cls: 0.235  loss_box_reg: 0.2268  loss_mask: 0.1777  loss_rpn_cls: 0.001799  loss_rpn_loc: 0.007475    time: 0.3811  last_time: 0.3807  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:55:04 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 1919  total_loss: 0.6563  loss_cls: 0.2303  loss_box_reg: 0.2247  loss_mask: 0.1637  loss_rpn_cls: 0.0007576  loss_rpn_loc: 0.006328    time: 0.3811  last_time: 0.3969  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:55:12 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 1939  total_loss: 0.6315  loss_cls: 0.2512  loss_box_reg: 0.23  loss_mask: 0.1553  loss_rpn_cls: 0.001272  loss_rpn_loc: 0.005837    time: 0.3814  last_time: 0.4133  data_time: 0.0013  last_data_time: 0.0020   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:55:20 d2.utils.events]: \u001b[0m eta: 0:06:47  iter: 1959  total_loss: 0.6141  loss_cls: 0.232  loss_box_reg: 0.1963  loss_mask: 0.1356  loss_rpn_cls: 0.0007613  loss_rpn_loc: 0.005409    time: 0.3818  last_time: 0.3300  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:55:28 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 1979  total_loss: 0.751  loss_cls: 0.2426  loss_box_reg: 0.2348  loss_mask: 0.1818  loss_rpn_cls: 0.00114  loss_rpn_loc: 0.01484    time: 0.3819  last_time: 0.3744  data_time: 0.0013  last_data_time: 0.0009   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:55:36 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 1999  total_loss: 0.6809  loss_cls: 0.2287  loss_box_reg: 0.2306  loss_mask: 0.1375  loss_rpn_cls: 0.0007936  loss_rpn_loc: 0.008531    time: 0.3820  last_time: 0.4310  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:55:44 d2.utils.events]: \u001b[0m eta: 0:06:24  iter: 2019  total_loss: 0.6399  loss_cls: 0.1765  loss_box_reg: 0.222  loss_mask: 0.1429  loss_rpn_cls: 0.001159  loss_rpn_loc: 0.008    time: 0.3821  last_time: 0.3517  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:55:52 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 2039  total_loss: 0.7479  loss_cls: 0.2564  loss_box_reg: 0.2468  loss_mask: 0.1755  loss_rpn_cls: 0.0006137  loss_rpn_loc: 0.01037    time: 0.3820  last_time: 0.3576  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:55:59 d2.utils.events]: \u001b[0m eta: 0:06:08  iter: 2059  total_loss: 0.6135  loss_cls: 0.2045  loss_box_reg: 0.2212  loss_mask: 0.161  loss_rpn_cls: 0.00151  loss_rpn_loc: 0.00715    time: 0.3821  last_time: 0.3986  data_time: 0.0012  last_data_time: 0.0015   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:56:07 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 2079  total_loss: 0.7428  loss_cls: 0.2468  loss_box_reg: 0.2816  loss_mask: 0.1806  loss_rpn_cls: 0.0003726  loss_rpn_loc: 0.01052    time: 0.3823  last_time: 0.4137  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:56:16 d2.utils.events]: \u001b[0m eta: 0:05:54  iter: 2099  total_loss: 0.6548  loss_cls: 0.2423  loss_box_reg: 0.2799  loss_mask: 0.1925  loss_rpn_cls: 0.0005942  loss_rpn_loc: 0.008551    time: 0.3825  last_time: 0.4091  data_time: 0.0013  last_data_time: 0.0016   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:56:23 d2.utils.events]: \u001b[0m eta: 0:05:46  iter: 2119  total_loss: 0.7538  loss_cls: 0.1935  loss_box_reg: 0.3148  loss_mask: 0.199  loss_rpn_cls: 0.0004066  loss_rpn_loc: 0.007529    time: 0.3826  last_time: 0.4231  data_time: 0.0013  last_data_time: 0.0019   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:56:31 d2.utils.events]: \u001b[0m eta: 0:05:39  iter: 2139  total_loss: 0.5818  loss_cls: 0.1843  loss_box_reg: 0.2248  loss_mask: 0.155  loss_rpn_cls: 0.0004423  loss_rpn_loc: 0.005274    time: 0.3828  last_time: 0.4189  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:56:40 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 2159  total_loss: 0.7825  loss_cls: 0.2218  loss_box_reg: 0.246  loss_mask: 0.1904  loss_rpn_cls: 0.002063  loss_rpn_loc: 0.009169    time: 0.3831  last_time: 0.3806  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:56:48 d2.utils.events]: \u001b[0m eta: 0:05:23  iter: 2179  total_loss: 0.5462  loss_cls: 0.1942  loss_box_reg: 0.2035  loss_mask: 0.144  loss_rpn_cls: 0.001821  loss_rpn_loc: 0.008101    time: 0.3833  last_time: 0.4447  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:56:56 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 2199  total_loss: 0.6565  loss_cls: 0.2535  loss_box_reg: 0.2521  loss_mask: 0.1776  loss_rpn_cls: 0.003165  loss_rpn_loc: 0.01027    time: 0.3834  last_time: 0.3545  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:57:03 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 2219  total_loss: 0.5423  loss_cls: 0.1729  loss_box_reg: 0.2304  loss_mask: 0.1729  loss_rpn_cls: 0.001516  loss_rpn_loc: 0.006261    time: 0.3834  last_time: 0.4514  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:57:11 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 2239  total_loss: 0.5815  loss_cls: 0.1943  loss_box_reg: 0.195  loss_mask: 0.1553  loss_rpn_cls: 0.0007721  loss_rpn_loc: 0.005237    time: 0.3834  last_time: 0.3998  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:57:19 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 2259  total_loss: 0.6345  loss_cls: 0.2195  loss_box_reg: 0.2049  loss_mask: 0.1514  loss_rpn_cls: 0.001488  loss_rpn_loc: 0.007152    time: 0.3836  last_time: 0.4156  data_time: 0.0014  last_data_time: 0.0016   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:57:27 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 2279  total_loss: 0.4997  loss_cls: 0.1854  loss_box_reg: 0.2061  loss_mask: 0.1344  loss_rpn_cls: 0.001211  loss_rpn_loc: 0.007206    time: 0.3837  last_time: 0.3563  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:57:35 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 2299  total_loss: 0.6139  loss_cls: 0.1907  loss_box_reg: 0.2242  loss_mask: 0.1767  loss_rpn_cls: 0.001029  loss_rpn_loc: 0.007629    time: 0.3838  last_time: 0.4485  data_time: 0.0017  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:57:43 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 2319  total_loss: 0.6555  loss_cls: 0.201  loss_box_reg: 0.2826  loss_mask: 0.1464  loss_rpn_cls: 0.000699  loss_rpn_loc: 0.008651    time: 0.3839  last_time: 0.4346  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:57:51 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 2339  total_loss: 0.5602  loss_cls: 0.2045  loss_box_reg: 0.1703  loss_mask: 0.1428  loss_rpn_cls: 0.002062  loss_rpn_loc: 0.006245    time: 0.3839  last_time: 0.4270  data_time: 0.0012  last_data_time: 0.0016   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:57:59 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 2359  total_loss: 0.58  loss_cls: 0.2225  loss_box_reg: 0.2185  loss_mask: 0.1639  loss_rpn_cls: 0.003775  loss_rpn_loc: 0.00844    time: 0.3841  last_time: 0.3730  data_time: 0.0015  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:58:07 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 2379  total_loss: 0.5304  loss_cls: 0.1454  loss_box_reg: 0.214  loss_mask: 0.128  loss_rpn_cls: 0.0009104  loss_rpn_loc: 0.006552    time: 0.3842  last_time: 0.4304  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:58:15 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 2399  total_loss: 0.5999  loss_cls: 0.167  loss_box_reg: 0.2546  loss_mask: 0.1607  loss_rpn_cls: 0.000631  loss_rpn_loc: 0.006612    time: 0.3842  last_time: 0.4230  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:58:23 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 2419  total_loss: 0.5091  loss_cls: 0.1279  loss_box_reg: 0.1929  loss_mask: 0.1513  loss_rpn_cls: 0.001727  loss_rpn_loc: 0.007296    time: 0.3844  last_time: 0.3854  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:58:31 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 2439  total_loss: 0.5351  loss_cls: 0.1387  loss_box_reg: 0.222  loss_mask: 0.1837  loss_rpn_cls: 0.0006074  loss_rpn_loc: 0.007429    time: 0.3846  last_time: 0.4505  data_time: 0.0015  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:58:39 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 2459  total_loss: 0.4982  loss_cls: 0.1453  loss_box_reg: 0.1803  loss_mask: 0.1178  loss_rpn_cls: 0.0003934  loss_rpn_loc: 0.00504    time: 0.3848  last_time: 0.3564  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:58:47 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 2479  total_loss: 0.7186  loss_cls: 0.2129  loss_box_reg: 0.2457  loss_mask: 0.142  loss_rpn_cls: 0.0009019  loss_rpn_loc: 0.01052    time: 0.3849  last_time: 0.4286  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:58:55 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 2499  total_loss: 0.5328  loss_cls: 0.1766  loss_box_reg: 0.2548  loss_mask: 0.1361  loss_rpn_cls: 0.0006873  loss_rpn_loc: 0.006219    time: 0.3850  last_time: 0.4090  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:59:03 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 2519  total_loss: 0.6781  loss_cls: 0.204  loss_box_reg: 0.2155  loss_mask: 0.1867  loss_rpn_cls: 0.00161  loss_rpn_loc: 0.01    time: 0.3851  last_time: 0.3697  data_time: 0.0014  last_data_time: 0.0016   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:59:10 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 2539  total_loss: 0.6365  loss_cls: 0.1833  loss_box_reg: 0.2433  loss_mask: 0.1859  loss_rpn_cls: 0.0001286  loss_rpn_loc: 0.009101    time: 0.3850  last_time: 0.4301  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:59:18 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 2559  total_loss: 0.516  loss_cls: 0.1615  loss_box_reg: 0.2091  loss_mask: 0.1514  loss_rpn_cls: 0.0006698  loss_rpn_loc: 0.01002    time: 0.3851  last_time: 0.4023  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:59:26 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 2579  total_loss: 0.5523  loss_cls: 0.1802  loss_box_reg: 0.2201  loss_mask: 0.1457  loss_rpn_cls: 0.0007725  loss_rpn_loc: 0.005878    time: 0.3850  last_time: 0.3385  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:59:34 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 2599  total_loss: 0.5702  loss_cls: 0.1916  loss_box_reg: 0.1802  loss_mask: 0.1486  loss_rpn_cls: 0.0009328  loss_rpn_loc: 0.006037    time: 0.3851  last_time: 0.3908  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:59:42 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 2619  total_loss: 0.6704  loss_cls: 0.2008  loss_box_reg: 0.2343  loss_mask: 0.1683  loss_rpn_cls: 0.000163  loss_rpn_loc: 0.00797    time: 0.3851  last_time: 0.4166  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:59:49 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 2639  total_loss: 0.518  loss_cls: 0.1708  loss_box_reg: 0.1832  loss_mask: 0.1289  loss_rpn_cls: 0.0006196  loss_rpn_loc: 0.005405    time: 0.3852  last_time: 0.4217  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 09:59:57 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 2659  total_loss: 0.6166  loss_cls: 0.189  loss_box_reg: 0.2389  loss_mask: 0.1772  loss_rpn_cls: 0.0002417  loss_rpn_loc: 0.008784    time: 0.3851  last_time: 0.3659  data_time: 0.0013  last_data_time: 0.0009   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:00:05 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 2679  total_loss: 0.6546  loss_cls: 0.2231  loss_box_reg: 0.2296  loss_mask: 0.1717  loss_rpn_cls: 0.002007  loss_rpn_loc: 0.009138    time: 0.3851  last_time: 0.4194  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:00:12 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 2699  total_loss: 0.5739  loss_cls: 0.2145  loss_box_reg: 0.1782  loss_mask: 0.1552  loss_rpn_cls: 0.003266  loss_rpn_loc: 0.00706    time: 0.3851  last_time: 0.4170  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:00:20 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 2719  total_loss: 0.5808  loss_cls: 0.1891  loss_box_reg: 0.2289  loss_mask: 0.1468  loss_rpn_cls: 0.0004804  loss_rpn_loc: 0.007374    time: 0.3852  last_time: 0.3274  data_time: 0.0014  last_data_time: 0.0017   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:00:28 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 2739  total_loss: 0.4726  loss_cls: 0.1409  loss_box_reg: 0.1827  loss_mask: 0.137  loss_rpn_cls: 0.0004206  loss_rpn_loc: 0.009196    time: 0.3854  last_time: 0.3982  data_time: 0.0015  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:00:37 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 2759  total_loss: 0.4642  loss_cls: 0.1467  loss_box_reg: 0.215  loss_mask: 0.1504  loss_rpn_cls: 0.0003767  loss_rpn_loc: 0.006868    time: 0.3855  last_time: 0.4254  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:00:45 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 2779  total_loss: 0.5568  loss_cls: 0.1408  loss_box_reg: 0.2167  loss_mask: 0.1446  loss_rpn_cls: 3.302e-05  loss_rpn_loc: 0.005613    time: 0.3857  last_time: 0.4282  data_time: 0.0014  last_data_time: 0.0009   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:00:53 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 2799  total_loss: 0.5944  loss_cls: 0.185  loss_box_reg: 0.2192  loss_mask: 0.1841  loss_rpn_cls: 0.001094  loss_rpn_loc: 0.006768    time: 0.3859  last_time: 0.4464  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:01:01 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 2819  total_loss: 0.625  loss_cls: 0.1366  loss_box_reg: 0.2184  loss_mask: 0.1567  loss_rpn_cls: 0.002031  loss_rpn_loc: 0.006275    time: 0.3860  last_time: 0.3310  data_time: 0.0014  last_data_time: 0.0015   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:01:09 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 2839  total_loss: 0.5617  loss_cls: 0.1857  loss_box_reg: 0.2117  loss_mask: 0.1559  loss_rpn_cls: 0.0001734  loss_rpn_loc: 0.01074    time: 0.3861  last_time: 0.4434  data_time: 0.0013  last_data_time: 0.0017   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:01:17 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 2859  total_loss: 0.4891  loss_cls: 0.193  loss_box_reg: 0.1888  loss_mask: 0.1427  loss_rpn_cls: 0.0008087  loss_rpn_loc: 0.009755    time: 0.3863  last_time: 0.4226  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:01:25 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 2879  total_loss: 0.5862  loss_cls: 0.1919  loss_box_reg: 0.1834  loss_mask: 0.1385  loss_rpn_cls: 0.00184  loss_rpn_loc: 0.007621    time: 0.3864  last_time: 0.3602  data_time: 0.0014  last_data_time: 0.0013   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:01:34 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 2899  total_loss: 0.6929  loss_cls: 0.1801  loss_box_reg: 0.2337  loss_mask: 0.1648  loss_rpn_cls: 0.002925  loss_rpn_loc: 0.008741    time: 0.3865  last_time: 0.3647  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:01:41 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 2919  total_loss: 0.4726  loss_cls: 0.1563  loss_box_reg: 0.2114  loss_mask: 0.1379  loss_rpn_cls: 0.001429  loss_rpn_loc: 0.003984    time: 0.3865  last_time: 0.4102  data_time: 0.0013  last_data_time: 0.0009   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:01:49 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 2939  total_loss: 0.6437  loss_cls: 0.2371  loss_box_reg: 0.247  loss_mask: 0.1768  loss_rpn_cls: 0.001644  loss_rpn_loc: 0.006843    time: 0.3865  last_time: 0.4032  data_time: 0.0014  last_data_time: 0.0015   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:01:57 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 2959  total_loss: 0.5636  loss_cls: 0.1847  loss_box_reg: 0.2036  loss_mask: 0.1426  loss_rpn_cls: 0.001117  loss_rpn_loc: 0.007407    time: 0.3866  last_time: 0.3924  data_time: 0.0014  last_data_time: 0.0016   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:02:05 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 2979  total_loss: 0.4913  loss_cls: 0.1359  loss_box_reg: 0.2074  loss_mask: 0.1528  loss_rpn_cls: 0.000673  loss_rpn_loc: 0.007402    time: 0.3866  last_time: 0.3587  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:03:17 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2999  total_loss: 0.5398  loss_cls: 0.1443  loss_box_reg: 0.199  loss_mask: 0.1602  loss_rpn_cls: 0.001734  loss_rpn_loc: 0.007116    time: 0.3867  last_time: 0.4268  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00025  max_mem: 2317M\n",
      "\u001b[32m[05/14 10:03:17 d2.engine.hooks]: \u001b[0mOverall training speed: 2998 iterations in 0:19:19 (0.3867 s / it)\n",
      "\u001b[32m[05/14 10:03:17 d2.engine.hooks]: \u001b[0mTotal training time: 0:20:24 (0:01:05 on hooks)\n",
      "\u001b[32m[05/14 10:03:17 d2.data.datasets.coco]: \u001b[0mLoaded 300 images in COCO format from dataset/annotation/valid_annotations.json\n",
      "\u001b[32m[05/14 10:03:17 d2.data.build]: \u001b[0mDistribution of instances among all 15 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Whole Chicken | 22           | Chicken Bre.. | 50           | Chicken Wings | 125          |\n",
      "|  Chicken Leg  | 92           | Chicken Thigh | 104          |      Egg      | 80           |\n",
      "|     Tofu      | 45           |   Lean Pork   | 58           |   Lean Beef   | 21           |\n",
      "| Sweet Potato  | 74           |   Potatoes    | 26           |     Rice      | 22           |\n",
      "| Whole Wheat.. | 50           |  White Bread  | 59           |   Broccoli    | 38           |\n",
      "|               |              |               |              |               |              |\n",
      "|     total     | 866          |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[05/14 10:03:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[05/14 10:03:17 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[05/14 10:03:17 d2.data.common]: \u001b[0mSerializing 300 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/14 10:03:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/14 10:03:17 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b896c94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/14 10:03:55 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[05/14 10:03:55 d2.data.datasets.coco]: \u001b[0mLoaded 300 images in COCO format from dataset/annotation/valid_annotations.json\n",
      "\u001b[32m[05/14 10:03:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[05/14 10:03:55 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[05/14 10:03:55 d2.data.common]: \u001b[0mSerializing 300 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/14 10:03:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[32m[05/14 10:03:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 batches\n",
      "\u001b[32m[05/14 10:04:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. Dataloading: 0.0005 s/iter. Inference: 0.0947 s/iter. Eval: 0.0042 s/iter. Total: 0.0995 s/iter. ETA=0:00:28\n",
      "\u001b[32m[05/14 10:04:06 d2.evaluation.evaluator]: \u001b[0mInference done 51/300. Dataloading: 0.0009 s/iter. Inference: 0.1051 s/iter. Eval: 0.0159 s/iter. Total: 0.1220 s/iter. ETA=0:00:30\n",
      "\u001b[32m[05/14 10:04:11 d2.evaluation.evaluator]: \u001b[0mInference done 95/300. Dataloading: 0.0008 s/iter. Inference: 0.0979 s/iter. Eval: 0.0194 s/iter. Total: 0.1181 s/iter. ETA=0:00:24\n",
      "\u001b[32m[05/14 10:04:16 d2.evaluation.evaluator]: \u001b[0mInference done 147/300. Dataloading: 0.0007 s/iter. Inference: 0.0938 s/iter. Eval: 0.0161 s/iter. Total: 0.1106 s/iter. ETA=0:00:16\n",
      "\u001b[32m[05/14 10:04:21 d2.evaluation.evaluator]: \u001b[0mInference done 197/300. Dataloading: 0.0007 s/iter. Inference: 0.0923 s/iter. Eval: 0.0148 s/iter. Total: 0.1079 s/iter. ETA=0:00:11\n",
      "\u001b[32m[05/14 10:04:26 d2.evaluation.evaluator]: \u001b[0mInference done 245/300. Dataloading: 0.0007 s/iter. Inference: 0.0919 s/iter. Eval: 0.0146 s/iter. Total: 0.1073 s/iter. ETA=0:00:05\n",
      "\u001b[32m[05/14 10:04:31 d2.evaluation.evaluator]: \u001b[0mInference done 292/300. Dataloading: 0.0007 s/iter. Inference: 0.0919 s/iter. Eval: 0.0146 s/iter. Total: 0.1072 s/iter. ETA=0:00:00\n",
      "\u001b[32m[05/14 10:04:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.465177 (0.116831 s / iter per device, on 1 devices)\n",
      "\u001b[32m[05/14 10:04:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:27 (0.091840 s / iter per device, on 1 devices)\n",
      "\u001b[32m[05/14 10:04:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[05/14 10:04:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_R101\\coco_instances_results.json\n",
      "\u001b[32m[05/14 10:04:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[05/14 10:04:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[05/14 10:04:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.23 seconds.\n",
      "\u001b[32m[05/14 10:04:35 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[05/14 10:04:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.689\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.545\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.640\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.406\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.669\n",
      "\u001b[32m[05/14 10:04:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 46.728 | 68.923 | 54.504 |  nan  | 32.027 | 48.216 |\n",
      "\u001b[32m[05/14 10:04:35 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[05/14 10:04:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category          | AP     | category       | AP     | category      | AP     |\n",
      "|:------------------|:-------|:---------------|:-------|:--------------|:-------|\n",
      "| Whole Chicken     | 45.621 | Chicken Breast | 53.501 | Chicken Wings | 15.619 |\n",
      "| Chicken Leg       | 42.262 | Chicken Thigh  | 44.401 | Egg           | 53.591 |\n",
      "| Tofu              | 27.363 | Lean Pork      | 30.899 | Lean Beef     | 62.640 |\n",
      "| Sweet Potato      | 52.246 | Potatoes       | 53.379 | Rice          | 75.106 |\n",
      "| Whole Wheat Bread | 41.702 | White Bread    | 49.046 | Broccoli      | 53.538 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[05/14 10:04:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[05/14 10:04:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[05/14 10:04:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[05/14 10:04:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.670\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.524\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.629\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.641\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657\n",
      "\u001b[32m[05/14 10:04:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 46.232 | 67.024 | 52.413 |  nan  | 24.708 | 48.063 |\n",
      "\u001b[32m[05/14 10:04:36 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[05/14 10:04:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category          | AP     | category       | AP     | category      | AP     |\n",
      "|:------------------|:-------|:---------------|:-------|:--------------|:-------|\n",
      "| Whole Chicken     | 43.280 | Chicken Breast | 56.713 | Chicken Wings | 13.117 |\n",
      "| Chicken Leg       | 38.492 | Chicken Thigh  | 45.461 | Egg           | 58.874 |\n",
      "| Tofu              | 29.951 | Lean Pork      | 32.021 | Lean Beef     | 66.273 |\n",
      "| Sweet Potato      | 45.746 | Potatoes       | 54.472 | Rice          | 81.417 |\n",
      "| Whole Wheat Bread | 34.223 | White Bread    | 42.567 | Broccoli      | 50.875 |\n",
      "OrderedDict({'bbox': {'AP': 46.7276814113382, 'AP50': 68.92346814987835, 'AP75': 54.504342620672475, 'APs': nan, 'APm': 32.02654355393883, 'APl': 48.21617219951545, 'AP-Whole Chicken': 45.621037118809014, 'AP-Chicken Breast': 53.50139090337947, 'AP-Chicken Wings': 15.618973433023854, 'AP-Chicken Leg': 42.26211437436807, 'AP-Chicken Thigh': 44.4012978345563, 'AP-Egg': 53.591485767572955, 'AP-Tofu': 27.363007755841164, 'AP-Lean Pork': 30.89887577026813, 'AP-Lean Beef': 62.639992990895735, 'AP-Sweet Potato': 52.24587702828287, 'AP-Potatoes': 53.37867779225576, 'AP-Rice': 75.10623834386978, 'AP-Whole Wheat Bread': 41.7024135385546, 'AP-White Bread': 49.0455309117556, 'AP-Broccoli': 53.538307606639826}, 'segm': {'AP': 46.23216737723983, 'AP50': 67.02412662225545, 'AP75': 52.41337896405852, 'APs': nan, 'APm': 24.708224233827405, 'APl': 48.063385654668394, 'AP-Whole Chicken': 43.280079450252714, 'AP-Chicken Breast': 56.7126221499967, 'AP-Chicken Wings': 13.11706487109546, 'AP-Chicken Leg': 38.49164870759242, 'AP-Chicken Thigh': 45.4609196013818, 'AP-Egg': 58.87409200876548, 'AP-Tofu': 29.950806316661627, 'AP-Lean Pork': 32.02144020078785, 'AP-Lean Beef': 66.27337410534848, 'AP-Sweet Potato': 45.74585725051593, 'AP-Potatoes': 54.4718045641139, 'AP-Rice': 81.4171257351299, 'AP-Whole Wheat Bread': 34.22343282405323, 'AP-White Bread': 42.56677366371434, 'AP-Broccoli': 50.87546920918773}})\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "evaluator = COCOEvaluator(\"food_val\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "val_loader = build_detection_test_loader(cfg, \"food_val\")\n",
    "print(inference_on_dataset(trainer.model, val_loader, evaluator))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foodenv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
