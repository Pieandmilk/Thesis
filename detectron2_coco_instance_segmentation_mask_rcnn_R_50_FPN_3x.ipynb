{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectron2 is working!\n"
     ]
    }
   ],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "print(\"Detectron2 is working!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registering Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# Unregister the dataset if it's already registered\n",
    "for d in [\"food_train\", \"food_val\"]:\n",
    "    if d in DatasetCatalog.list():\n",
    "        DatasetCatalog.remove(d)\n",
    "        MetadataCatalog.remove(d)\n",
    "\n",
    "# Now register again with correct paths\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(\"food_train\", {}, r\"dataset/annotation/train_annotation.json\", \"dataset/train\")\n",
    "register_coco_instances(\"food_val\", {}, r\"dataset/annotation/valid_annotations.json\", \"dataset/valid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "import os\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.DATASETS.TRAIN = (\"food_train\",)\n",
    "cfg.DATASETS.TEST = (\"food_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # pre-trained COCO weights\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 3000    # You can increase for better training\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 15  # Replace N with your number of classes\n",
    "cfg.OUTPUT_DIR = \"./outputR50\"\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/12 17:35:02 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=16, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=60, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[05/12 17:35:03 d2.data.datasets.coco]: \u001b[0mLoaded 1200 images in COCO format from dataset/annotation/train_annotation.json\n",
      "\u001b[32m[05/12 17:35:03 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1200 images left.\n",
      "\u001b[32m[05/12 17:35:03 d2.data.build]: \u001b[0mDistribution of instances among all 15 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Whole Chicken | 81           | Chicken Bre.. | 202          | Chicken Wings | 399          |\n",
      "|  Chicken Leg  | 395          | Chicken Thigh | 366          |      Egg      | 177          |\n",
      "|     Tofu      | 120          |   Lean Pork   | 216          |   Lean Beef   | 89           |\n",
      "| Sweet Potato  | 256          |   Potatoes    | 97           |     Rice      | 83           |\n",
      "| Whole Wheat.. | 192          |  White Bread  | 227          |   Broccolli   | 162          |\n",
      "|               |              |               |              |               |              |\n",
      "|     total     | 3062         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[05/12 17:35:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[05/12 17:35:03 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[05/12 17:35:03 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[05/12 17:35:03 d2.data.common]: \u001b[0mSerializing 1200 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/12 17:35:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.40 MiB\n",
      "\u001b[32m[05/12 17:35:03 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/12 17:35:03 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[05/12 17:35:03 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_f10217.pkl: 178MB [00:07, 25.2MB/s]                              \n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (60, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (60,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (15, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/12 17:35:10 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\Desktop\\Thesis\\foodenv312\\Lib\\site-packages\\torch\\functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4316.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/12 17:35:23 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 19  total_loss: 4.135  loss_cls: 2.766  loss_box_reg: 0.6331  loss_mask: 0.6927  loss_rpn_cls: 0.01795  loss_rpn_loc: 0.01    time: 0.2884  last_time: 0.2924  data_time: 0.2194  last_data_time: 0.0011   lr: 4.9953e-06  max_mem: 1586M\n",
      "\u001b[32m[05/12 17:35:29 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 39  total_loss: 3.935  loss_cls: 2.641  loss_box_reg: 0.6335  loss_mask: 0.6918  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.01275    time: 0.2833  last_time: 0.2817  data_time: 0.0013  last_data_time: 0.0009   lr: 9.9902e-06  max_mem: 1586M\n",
      "\u001b[32m[05/12 17:35:35 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 59  total_loss: 3.789  loss_cls: 2.311  loss_box_reg: 0.7041  loss_mask: 0.6906  loss_rpn_cls: 0.01364  loss_rpn_loc: 0.01425    time: 0.2850  last_time: 0.2921  data_time: 0.0013  last_data_time: 0.0009   lr: 1.4985e-05  max_mem: 1588M\n",
      "\u001b[32m[05/12 17:35:41 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 79  total_loss: 3.268  loss_cls: 1.871  loss_box_reg: 0.6714  loss_mask: 0.686  loss_rpn_cls: 0.007969  loss_rpn_loc: 0.01342    time: 0.2833  last_time: 0.2496  data_time: 0.0015  last_data_time: 0.0010   lr: 1.998e-05  max_mem: 1588M\n",
      "\u001b[32m[05/12 17:35:46 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 99  total_loss: 2.765  loss_cls: 1.351  loss_box_reg: 0.6381  loss_mask: 0.6831  loss_rpn_cls: 0.006942  loss_rpn_loc: 0.01136    time: 0.2807  last_time: 0.2810  data_time: 0.0012  last_data_time: 0.0011   lr: 2.4975e-05  max_mem: 1588M\n",
      "\u001b[32m[05/12 17:35:52 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 119  total_loss: 2.549  loss_cls: 1.03  loss_box_reg: 0.7732  loss_mask: 0.6755  loss_rpn_cls: 0.009885  loss_rpn_loc: 0.01365    time: 0.2810  last_time: 0.2716  data_time: 0.0013  last_data_time: 0.0012   lr: 2.997e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:35:57 d2.utils.events]: \u001b[0m eta: 0:13:21  iter: 139  total_loss: 2.176  loss_cls: 0.8177  loss_box_reg: 0.6623  loss_mask: 0.6694  loss_rpn_cls: 0.005599  loss_rpn_loc: 0.0139    time: 0.2810  last_time: 0.2553  data_time: 0.0012  last_data_time: 0.0009   lr: 3.4965e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:36:03 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 159  total_loss: 2.318  loss_cls: 0.8666  loss_box_reg: 0.7717  loss_mask: 0.6682  loss_rpn_cls: 0.007446  loss_rpn_loc: 0.011    time: 0.2776  last_time: 0.2496  data_time: 0.0011  last_data_time: 0.0010   lr: 3.996e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:36:08 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 179  total_loss: 2.153  loss_cls: 0.7634  loss_box_reg: 0.7181  loss_mask: 0.653  loss_rpn_cls: 0.00896  loss_rpn_loc: 0.01103    time: 0.2754  last_time: 0.2317  data_time: 0.0011  last_data_time: 0.0009   lr: 4.4955e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:36:13 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 199  total_loss: 2.21  loss_cls: 0.7825  loss_box_reg: 0.7418  loss_mask: 0.6414  loss_rpn_cls: 0.007559  loss_rpn_loc: 0.008818    time: 0.2733  last_time: 0.2473  data_time: 0.0011  last_data_time: 0.0009   lr: 4.995e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:36:18 d2.utils.events]: \u001b[0m eta: 0:12:39  iter: 219  total_loss: 2.156  loss_cls: 0.824  loss_box_reg: 0.7178  loss_mask: 0.6418  loss_rpn_cls: 0.007645  loss_rpn_loc: 0.01333    time: 0.2726  last_time: 0.2485  data_time: 0.0012  last_data_time: 0.0012   lr: 5.4945e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:36:23 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 239  total_loss: 2.151  loss_cls: 0.755  loss_box_reg: 0.7554  loss_mask: 0.63  loss_rpn_cls: 0.00553  loss_rpn_loc: 0.009097    time: 0.2720  last_time: 0.2464  data_time: 0.0011  last_data_time: 0.0013   lr: 5.994e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:36:29 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 259  total_loss: 1.932  loss_cls: 0.6686  loss_box_reg: 0.642  loss_mask: 0.6091  loss_rpn_cls: 0.005991  loss_rpn_loc: 0.01271    time: 0.2731  last_time: 0.3026  data_time: 0.0012  last_data_time: 0.0015   lr: 6.4935e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:36:35 d2.utils.events]: \u001b[0m eta: 0:12:29  iter: 279  total_loss: 2.065  loss_cls: 0.7448  loss_box_reg: 0.7357  loss_mask: 0.6004  loss_rpn_cls: 0.00564  loss_rpn_loc: 0.01022    time: 0.2736  last_time: 0.2368  data_time: 0.0012  last_data_time: 0.0010   lr: 6.993e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:36:40 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 299  total_loss: 2.063  loss_cls: 0.703  loss_box_reg: 0.7257  loss_mask: 0.5552  loss_rpn_cls: 0.003893  loss_rpn_loc: 0.01201    time: 0.2738  last_time: 0.2705  data_time: 0.0013  last_data_time: 0.0011   lr: 7.4925e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:36:46 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 319  total_loss: 2.044  loss_cls: 0.7246  loss_box_reg: 0.7812  loss_mask: 0.5495  loss_rpn_cls: 0.008333  loss_rpn_loc: 0.01617    time: 0.2739  last_time: 0.2949  data_time: 0.0013  last_data_time: 0.0011   lr: 7.992e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:36:52 d2.utils.events]: \u001b[0m eta: 0:12:15  iter: 339  total_loss: 1.888  loss_cls: 0.6332  loss_box_reg: 0.6662  loss_mask: 0.5487  loss_rpn_cls: 0.00721  loss_rpn_loc: 0.01276    time: 0.2746  last_time: 0.2819  data_time: 0.0015  last_data_time: 0.0011   lr: 8.4915e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:36:57 d2.utils.events]: \u001b[0m eta: 0:12:07  iter: 359  total_loss: 1.936  loss_cls: 0.7253  loss_box_reg: 0.722  loss_mask: 0.5138  loss_rpn_cls: 0.006387  loss_rpn_loc: 0.01162    time: 0.2745  last_time: 0.2654  data_time: 0.0013  last_data_time: 0.0012   lr: 8.991e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:37:02 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 379  total_loss: 1.837  loss_cls: 0.6626  loss_box_reg: 0.6869  loss_mask: 0.4772  loss_rpn_cls: 0.002535  loss_rpn_loc: 0.008745    time: 0.2745  last_time: 0.2731  data_time: 0.0013  last_data_time: 0.0011   lr: 9.4905e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:37:08 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 399  total_loss: 2.035  loss_cls: 0.7348  loss_box_reg: 0.7137  loss_mask: 0.4788  loss_rpn_cls: 0.004455  loss_rpn_loc: 0.01031    time: 0.2743  last_time: 0.2314  data_time: 0.0013  last_data_time: 0.0013   lr: 9.99e-05  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:37:14 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 419  total_loss: 1.937  loss_cls: 0.7438  loss_box_reg: 0.7228  loss_mask: 0.4748  loss_rpn_cls: 0.00862  loss_rpn_loc: 0.01483    time: 0.2748  last_time: 0.2939  data_time: 0.0013  last_data_time: 0.0013   lr: 0.0001049  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:37:19 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 439  total_loss: 1.773  loss_cls: 0.6255  loss_box_reg: 0.6706  loss_mask: 0.4308  loss_rpn_cls: 0.004322  loss_rpn_loc: 0.01358    time: 0.2753  last_time: 0.3028  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00010989  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:37:25 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 459  total_loss: 1.702  loss_cls: 0.5949  loss_box_reg: 0.7031  loss_mask: 0.4181  loss_rpn_cls: 0.002744  loss_rpn_loc: 0.008898    time: 0.2756  last_time: 0.2862  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00011489  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:37:30 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 479  total_loss: 1.676  loss_cls: 0.6091  loss_box_reg: 0.6424  loss_mask: 0.385  loss_rpn_cls: 0.004201  loss_rpn_loc: 0.01101    time: 0.2753  last_time: 0.2462  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00011988  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:37:36 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 499  total_loss: 1.838  loss_cls: 0.649  loss_box_reg: 0.6305  loss_mask: 0.4203  loss_rpn_cls: 0.005842  loss_rpn_loc: 0.01342    time: 0.2759  last_time: 0.2910  data_time: 0.0014  last_data_time: 0.0013   lr: 0.00012488  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:37:42 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 519  total_loss: 1.951  loss_cls: 0.7529  loss_box_reg: 0.7503  loss_mask: 0.3592  loss_rpn_cls: 0.004338  loss_rpn_loc: 0.01342    time: 0.2764  last_time: 0.2974  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00012987  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:37:48 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 539  total_loss: 1.705  loss_cls: 0.656  loss_box_reg: 0.7362  loss_mask: 0.3168  loss_rpn_cls: 0.004807  loss_rpn_loc: 0.01024    time: 0.2765  last_time: 0.3106  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00013487  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:37:53 d2.utils.events]: \u001b[0m eta: 0:11:18  iter: 559  total_loss: 1.686  loss_cls: 0.6525  loss_box_reg: 0.6615  loss_mask: 0.3117  loss_rpn_cls: 0.002904  loss_rpn_loc: 0.01522    time: 0.2767  last_time: 0.2790  data_time: 0.0011  last_data_time: 0.0009   lr: 0.00013986  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:37:59 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 579  total_loss: 1.658  loss_cls: 0.6441  loss_box_reg: 0.6507  loss_mask: 0.282  loss_rpn_cls: 0.002657  loss_rpn_loc: 0.00837    time: 0.2770  last_time: 0.2990  data_time: 0.0011  last_data_time: 0.0010   lr: 0.00014486  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:38:05 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 599  total_loss: 1.625  loss_cls: 0.5979  loss_box_reg: 0.6714  loss_mask: 0.2891  loss_rpn_cls: 0.001769  loss_rpn_loc: 0.01371    time: 0.2772  last_time: 0.2996  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00014985  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:38:10 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 619  total_loss: 1.508  loss_cls: 0.6196  loss_box_reg: 0.6784  loss_mask: 0.2566  loss_rpn_cls: 0.003316  loss_rpn_loc: 0.01324    time: 0.2769  last_time: 0.2292  data_time: 0.0011  last_data_time: 0.0011   lr: 0.00015485  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:38:15 d2.utils.events]: \u001b[0m eta: 0:10:56  iter: 639  total_loss: 1.465  loss_cls: 0.5239  loss_box_reg: 0.5971  loss_mask: 0.2188  loss_rpn_cls: 0.003794  loss_rpn_loc: 0.01257    time: 0.2768  last_time: 0.2728  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00015984  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:38:21 d2.utils.events]: \u001b[0m eta: 0:10:51  iter: 659  total_loss: 1.402  loss_cls: 0.5879  loss_box_reg: 0.6285  loss_mask: 0.2233  loss_rpn_cls: 0.003783  loss_rpn_loc: 0.01652    time: 0.2773  last_time: 0.3393  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00016484  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:38:27 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 679  total_loss: 1.341  loss_cls: 0.4955  loss_box_reg: 0.5758  loss_mask: 0.211  loss_rpn_cls: 0.004573  loss_rpn_loc: 0.01514    time: 0.2777  last_time: 0.2803  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00016983  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:38:33 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 699  total_loss: 1.574  loss_cls: 0.5938  loss_box_reg: 0.6314  loss_mask: 0.2323  loss_rpn_cls: 0.009779  loss_rpn_loc: 0.02004    time: 0.2783  last_time: 0.2839  data_time: 0.0011  last_data_time: 0.0013   lr: 0.00017483  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:38:39 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 719  total_loss: 1.286  loss_cls: 0.5636  loss_box_reg: 0.5102  loss_mask: 0.2293  loss_rpn_cls: 0.002422  loss_rpn_loc: 0.01976    time: 0.2787  last_time: 0.3168  data_time: 0.0014  last_data_time: 0.0021   lr: 0.00017982  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:38:45 d2.utils.events]: \u001b[0m eta: 0:10:33  iter: 739  total_loss: 1.152  loss_cls: 0.4754  loss_box_reg: 0.5114  loss_mask: 0.1696  loss_rpn_cls: 0.001727  loss_rpn_loc: 0.01049    time: 0.2792  last_time: 0.3123  data_time: 0.0014  last_data_time: 0.0013   lr: 0.00018482  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:38:51 d2.utils.events]: \u001b[0m eta: 0:10:28  iter: 759  total_loss: 1.214  loss_cls: 0.515  loss_box_reg: 0.4676  loss_mask: 0.2212  loss_rpn_cls: 0.002097  loss_rpn_loc: 0.02073    time: 0.2794  last_time: 0.3005  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00018981  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:38:57 d2.utils.events]: \u001b[0m eta: 0:10:24  iter: 779  total_loss: 1.095  loss_cls: 0.3952  loss_box_reg: 0.4641  loss_mask: 0.1994  loss_rpn_cls: 0.001238  loss_rpn_loc: 0.009994    time: 0.2797  last_time: 0.2835  data_time: 0.0015  last_data_time: 0.0017   lr: 0.00019481  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:39:02 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 799  total_loss: 1.456  loss_cls: 0.6129  loss_box_reg: 0.5165  loss_mask: 0.2586  loss_rpn_cls: 0.004407  loss_rpn_loc: 0.02011    time: 0.2797  last_time: 0.2739  data_time: 0.0014  last_data_time: 0.0015   lr: 0.0001998  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:39:08 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 819  total_loss: 1.262  loss_cls: 0.464  loss_box_reg: 0.4494  loss_mask: 0.2628  loss_rpn_cls: 0.003221  loss_rpn_loc: 0.01875    time: 0.2800  last_time: 0.2799  data_time: 0.0012  last_data_time: 0.0014   lr: 0.0002048  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:39:14 d2.utils.events]: \u001b[0m eta: 0:10:07  iter: 839  total_loss: 1.181  loss_cls: 0.5546  loss_box_reg: 0.4225  loss_mask: 0.2055  loss_rpn_cls: 0.006481  loss_rpn_loc: 0.01641    time: 0.2800  last_time: 0.2635  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00020979  max_mem: 1589M\n",
      "\u001b[32m[05/12 17:39:19 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 859  total_loss: 1.314  loss_cls: 0.5444  loss_box_reg: 0.5272  loss_mask: 0.2179  loss_rpn_cls: 0.0056  loss_rpn_loc: 0.01324    time: 0.2804  last_time: 0.3098  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00021479  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:39:25 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 879  total_loss: 1.135  loss_cls: 0.4412  loss_box_reg: 0.4216  loss_mask: 0.2427  loss_rpn_cls: 0.002886  loss_rpn_loc: 0.0105    time: 0.2804  last_time: 0.3083  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00021978  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:39:31 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 899  total_loss: 1.034  loss_cls: 0.3971  loss_box_reg: 0.3609  loss_mask: 0.2245  loss_rpn_cls: 0.003426  loss_rpn_loc: 0.01003    time: 0.2803  last_time: 0.3069  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00022478  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:39:37 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 919  total_loss: 0.882  loss_cls: 0.3689  loss_box_reg: 0.3516  loss_mask: 0.1706  loss_rpn_cls: 0.005504  loss_rpn_loc: 0.008597    time: 0.2807  last_time: 0.2724  data_time: 0.0014  last_data_time: 0.0020   lr: 0.00022977  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:39:42 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 939  total_loss: 1.011  loss_cls: 0.4706  loss_box_reg: 0.3915  loss_mask: 0.1627  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.01704    time: 0.2807  last_time: 0.2924  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00023477  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:39:48 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 959  total_loss: 1.082  loss_cls: 0.5067  loss_box_reg: 0.3867  loss_mask: 0.2286  loss_rpn_cls: 0.001674  loss_rpn_loc: 0.008619    time: 0.2810  last_time: 0.3004  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00023976  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:39:54 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 979  total_loss: 0.8864  loss_cls: 0.327  loss_box_reg: 0.3458  loss_mask: 0.2181  loss_rpn_cls: 0.003864  loss_rpn_loc: 0.0149    time: 0.2811  last_time: 0.2960  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00024476  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:40:00 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 999  total_loss: 0.9759  loss_cls: 0.3948  loss_box_reg: 0.3653  loss_mask: 0.1722  loss_rpn_cls: 0.008143  loss_rpn_loc: 0.0126    time: 0.2813  last_time: 0.2768  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00024975  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:40:06 d2.utils.events]: \u001b[0m eta: 0:09:20  iter: 1019  total_loss: 1.089  loss_cls: 0.4497  loss_box_reg: 0.3596  loss_mask: 0.2378  loss_rpn_cls: 0.005425  loss_rpn_loc: 0.01177    time: 0.2817  last_time: 0.3470  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:40:12 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 1039  total_loss: 0.9971  loss_cls: 0.4213  loss_box_reg: 0.394  loss_mask: 0.1893  loss_rpn_cls: 0.0008935  loss_rpn_loc: 0.01024    time: 0.2821  last_time: 0.2998  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:40:18 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 1059  total_loss: 0.8294  loss_cls: 0.3984  loss_box_reg: 0.2925  loss_mask: 0.206  loss_rpn_cls: 0.003658  loss_rpn_loc: 0.01056    time: 0.2824  last_time: 0.2376  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:40:24 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 1079  total_loss: 0.936  loss_cls: 0.3517  loss_box_reg: 0.2893  loss_mask: 0.1783  loss_rpn_cls: 0.001776  loss_rpn_loc: 0.01436    time: 0.2827  last_time: 0.3134  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:40:30 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 1099  total_loss: 0.956  loss_cls: 0.3298  loss_box_reg: 0.3741  loss_mask: 0.2246  loss_rpn_cls: 0.002162  loss_rpn_loc: 0.01357    time: 0.2829  last_time: 0.2693  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:40:36 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 1119  total_loss: 0.8823  loss_cls: 0.381  loss_box_reg: 0.3414  loss_mask: 0.1885  loss_rpn_cls: 0.002411  loss_rpn_loc: 0.008339    time: 0.2832  last_time: 0.3114  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:40:42 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 1139  total_loss: 0.9025  loss_cls: 0.3924  loss_box_reg: 0.3208  loss_mask: 0.1685  loss_rpn_cls: 0.0008697  loss_rpn_loc: 0.009096    time: 0.2836  last_time: 0.2915  data_time: 0.0016  last_data_time: 0.0014   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:40:48 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 1159  total_loss: 0.886  loss_cls: 0.3537  loss_box_reg: 0.2875  loss_mask: 0.1987  loss_rpn_cls: 0.001794  loss_rpn_loc: 0.01132    time: 0.2838  last_time: 0.3126  data_time: 0.0015  last_data_time: 0.0013   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:40:54 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 1179  total_loss: 0.9724  loss_cls: 0.3414  loss_box_reg: 0.3326  loss_mask: 0.1719  loss_rpn_cls: 0.003979  loss_rpn_loc: 0.008356    time: 0.2840  last_time: 0.2957  data_time: 0.0014  last_data_time: 0.0020   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:40:59 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 1199  total_loss: 0.8417  loss_cls: 0.3508  loss_box_reg: 0.3223  loss_mask: 0.1662  loss_rpn_cls: 0.001067  loss_rpn_loc: 0.0102    time: 0.2841  last_time: 0.3078  data_time: 0.0013  last_data_time: 0.0017   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:41:06 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 1219  total_loss: 0.7676  loss_cls: 0.2832  loss_box_reg: 0.3485  loss_mask: 0.1988  loss_rpn_cls: 0.001443  loss_rpn_loc: 0.0142    time: 0.2845  last_time: 0.3184  data_time: 0.0015  last_data_time: 0.0013   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:41:12 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 1239  total_loss: 0.969  loss_cls: 0.3803  loss_box_reg: 0.34  loss_mask: 0.1823  loss_rpn_cls: 0.002868  loss_rpn_loc: 0.01283    time: 0.2849  last_time: 0.2989  data_time: 0.0015  last_data_time: 0.0010   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:41:18 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 1259  total_loss: 0.9445  loss_cls: 0.3354  loss_box_reg: 0.3522  loss_mask: 0.1953  loss_rpn_cls: 0.005196  loss_rpn_loc: 0.01239    time: 0.2854  last_time: 0.2975  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:41:24 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 1279  total_loss: 0.7821  loss_cls: 0.2946  loss_box_reg: 0.3078  loss_mask: 0.1735  loss_rpn_cls: 0.0008169  loss_rpn_loc: 0.0122    time: 0.2857  last_time: 0.3129  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:41:30 d2.utils.events]: \u001b[0m eta: 0:08:14  iter: 1299  total_loss: 0.9807  loss_cls: 0.3477  loss_box_reg: 0.3283  loss_mask: 0.2227  loss_rpn_cls: 0.001577  loss_rpn_loc: 0.01017    time: 0.2857  last_time: 0.2838  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:41:36 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 1319  total_loss: 0.7274  loss_cls: 0.2897  loss_box_reg: 0.2884  loss_mask: 0.1528  loss_rpn_cls: 0.005276  loss_rpn_loc: 0.006772    time: 0.2859  last_time: 0.3176  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:41:42 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 1339  total_loss: 0.7484  loss_cls: 0.2258  loss_box_reg: 0.3081  loss_mask: 0.1805  loss_rpn_cls: 0.001948  loss_rpn_loc: 0.009366    time: 0.2861  last_time: 0.2987  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 1590M\n",
      "\u001b[32m[05/12 17:41:48 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 1359  total_loss: 0.7741  loss_cls: 0.3009  loss_box_reg: 0.2931  loss_mask: 0.1561  loss_rpn_cls: 0.001204  loss_rpn_loc: 0.009752    time: 0.2865  last_time: 0.2657  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:41:54 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 1379  total_loss: 0.8499  loss_cls: 0.2795  loss_box_reg: 0.2874  loss_mask: 0.186  loss_rpn_cls: 0.001663  loss_rpn_loc: 0.008043    time: 0.2868  last_time: 0.2854  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:42:01 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 1399  total_loss: 0.7678  loss_cls: 0.3052  loss_box_reg: 0.2956  loss_mask: 0.1485  loss_rpn_cls: 0.0008709  loss_rpn_loc: 0.007709    time: 0.2871  last_time: 0.2816  data_time: 0.0011  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:42:07 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 1419  total_loss: 0.6724  loss_cls: 0.2495  loss_box_reg: 0.2697  loss_mask: 0.1624  loss_rpn_cls: 0.00131  loss_rpn_loc: 0.01074    time: 0.2874  last_time: 0.3079  data_time: 0.0015  last_data_time: 0.0015   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:42:13 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 1439  total_loss: 0.7478  loss_cls: 0.3451  loss_box_reg: 0.2593  loss_mask: 0.149  loss_rpn_cls: 0.000597  loss_rpn_loc: 0.009372    time: 0.2876  last_time: 0.2965  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:42:19 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 1459  total_loss: 0.8699  loss_cls: 0.3491  loss_box_reg: 0.2933  loss_mask: 0.1856  loss_rpn_cls: 0.004641  loss_rpn_loc: 0.01126    time: 0.2876  last_time: 0.3026  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:42:24 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 1479  total_loss: 0.9033  loss_cls: 0.4097  loss_box_reg: 0.3054  loss_mask: 0.1793  loss_rpn_cls: 0.00224  loss_rpn_loc: 0.01033    time: 0.2877  last_time: 0.3146  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:42:30 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 1499  total_loss: 0.7621  loss_cls: 0.2795  loss_box_reg: 0.2566  loss_mask: 0.1639  loss_rpn_cls: 0.002582  loss_rpn_loc: 0.00836    time: 0.2878  last_time: 0.3145  data_time: 0.0011  last_data_time: 0.0009   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:42:36 d2.utils.events]: \u001b[0m eta: 0:07:18  iter: 1519  total_loss: 0.8631  loss_cls: 0.3103  loss_box_reg: 0.3123  loss_mask: 0.1845  loss_rpn_cls: 0.000395  loss_rpn_loc: 0.01048    time: 0.2879  last_time: 0.2970  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:42:42 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 1539  total_loss: 0.995  loss_cls: 0.3502  loss_box_reg: 0.3688  loss_mask: 0.2123  loss_rpn_cls: 0.005652  loss_rpn_loc: 0.009509    time: 0.2881  last_time: 0.2868  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:42:48 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 1559  total_loss: 0.8066  loss_cls: 0.2134  loss_box_reg: 0.3193  loss_mask: 0.1864  loss_rpn_cls: 0.002167  loss_rpn_loc: 0.01047    time: 0.2882  last_time: 0.2608  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:42:54 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 1579  total_loss: 0.6629  loss_cls: 0.2828  loss_box_reg: 0.2443  loss_mask: 0.1537  loss_rpn_cls: 0.001951  loss_rpn_loc: 0.01224    time: 0.2882  last_time: 0.3182  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:43:00 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 1599  total_loss: 0.7061  loss_cls: 0.2923  loss_box_reg: 0.2564  loss_mask: 0.1708  loss_rpn_cls: 0.00462  loss_rpn_loc: 0.01086    time: 0.2883  last_time: 0.2466  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:43:06 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 1619  total_loss: 0.6478  loss_cls: 0.2637  loss_box_reg: 0.2051  loss_mask: 0.1507  loss_rpn_cls: 0.002778  loss_rpn_loc: 0.006773    time: 0.2885  last_time: 0.3071  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:43:12 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 1639  total_loss: 0.7948  loss_cls: 0.2948  loss_box_reg: 0.3117  loss_mask: 0.1746  loss_rpn_cls: 0.00111  loss_rpn_loc: 0.0151    time: 0.2888  last_time: 0.3487  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:43:19 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 1659  total_loss: 0.8669  loss_cls: 0.3389  loss_box_reg: 0.3216  loss_mask: 0.1819  loss_rpn_cls: 0.005863  loss_rpn_loc: 0.0114    time: 0.2891  last_time: 0.2995  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:43:25 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 1679  total_loss: 0.7822  loss_cls: 0.3502  loss_box_reg: 0.2258  loss_mask: 0.1806  loss_rpn_cls: 0.002419  loss_rpn_loc: 0.01018    time: 0.2893  last_time: 0.2712  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:43:31 d2.utils.events]: \u001b[0m eta: 0:06:30  iter: 1699  total_loss: 0.7712  loss_cls: 0.277  loss_box_reg: 0.2687  loss_mask: 0.1839  loss_rpn_cls: 0.00259  loss_rpn_loc: 0.01052    time: 0.2894  last_time: 0.2803  data_time: 0.0015  last_data_time: 0.0015   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:43:37 d2.utils.events]: \u001b[0m eta: 0:06:24  iter: 1719  total_loss: 0.861  loss_cls: 0.3625  loss_box_reg: 0.305  loss_mask: 0.1809  loss_rpn_cls: 0.001246  loss_rpn_loc: 0.01302    time: 0.2896  last_time: 0.3291  data_time: 0.0015  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:43:43 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 1739  total_loss: 0.9801  loss_cls: 0.3548  loss_box_reg: 0.3481  loss_mask: 0.2038  loss_rpn_cls: 0.0005826  loss_rpn_loc: 0.01014    time: 0.2897  last_time: 0.2527  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:43:49 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 1759  total_loss: 0.7388  loss_cls: 0.3015  loss_box_reg: 0.2543  loss_mask: 0.1726  loss_rpn_cls: 0.002451  loss_rpn_loc: 0.0102    time: 0.2899  last_time: 0.3017  data_time: 0.0015  last_data_time: 0.0014   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:43:55 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 1779  total_loss: 0.8607  loss_cls: 0.2452  loss_box_reg: 0.3663  loss_mask: 0.2092  loss_rpn_cls: 0.003328  loss_rpn_loc: 0.008057    time: 0.2900  last_time: 0.2980  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:44:01 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 1799  total_loss: 0.8803  loss_cls: 0.3151  loss_box_reg: 0.2963  loss_mask: 0.2039  loss_rpn_cls: 0.002167  loss_rpn_loc: 0.0102    time: 0.2901  last_time: 0.3314  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:44:07 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 1819  total_loss: 0.8022  loss_cls: 0.2502  loss_box_reg: 0.2574  loss_mask: 0.1871  loss_rpn_cls: 0.001546  loss_rpn_loc: 0.01457    time: 0.2902  last_time: 0.3091  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:44:13 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 1839  total_loss: 0.7815  loss_cls: 0.3086  loss_box_reg: 0.2947  loss_mask: 0.1933  loss_rpn_cls: 0.002287  loss_rpn_loc: 0.01366    time: 0.2903  last_time: 0.2773  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:44:19 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 1859  total_loss: 0.6925  loss_cls: 0.213  loss_box_reg: 0.2652  loss_mask: 0.1732  loss_rpn_cls: 0.003662  loss_rpn_loc: 0.01114    time: 0.2905  last_time: 0.3166  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:44:25 d2.utils.events]: \u001b[0m eta: 0:05:39  iter: 1879  total_loss: 0.6415  loss_cls: 0.2413  loss_box_reg: 0.2547  loss_mask: 0.1625  loss_rpn_cls: 0.0005295  loss_rpn_loc: 0.00652    time: 0.2908  last_time: 0.3467  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:44:32 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 1899  total_loss: 0.8041  loss_cls: 0.2617  loss_box_reg: 0.2621  loss_mask: 0.2063  loss_rpn_cls: 0.001236  loss_rpn_loc: 0.008394    time: 0.2910  last_time: 0.3171  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:44:38 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 1919  total_loss: 0.7413  loss_cls: 0.2949  loss_box_reg: 0.2269  loss_mask: 0.172  loss_rpn_cls: 0.001524  loss_rpn_loc: 0.01186    time: 0.2911  last_time: 0.3395  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:44:44 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 1939  total_loss: 0.6783  loss_cls: 0.265  loss_box_reg: 0.2537  loss_mask: 0.1622  loss_rpn_cls: 0.002361  loss_rpn_loc: 0.01072    time: 0.2913  last_time: 0.2815  data_time: 0.0013  last_data_time: 0.0017   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:44:50 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 1959  total_loss: 0.6422  loss_cls: 0.2463  loss_box_reg: 0.2506  loss_mask: 0.1525  loss_rpn_cls: 0.002165  loss_rpn_loc: 0.006989    time: 0.2915  last_time: 0.2864  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:44:56 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 1979  total_loss: 0.7927  loss_cls: 0.3143  loss_box_reg: 0.3014  loss_mask: 0.196  loss_rpn_cls: 0.00197  loss_rpn_loc: 0.01674    time: 0.2916  last_time: 0.2808  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:45:02 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 1999  total_loss: 0.7111  loss_cls: 0.2259  loss_box_reg: 0.242  loss_mask: 0.16  loss_rpn_cls: 0.001407  loss_rpn_loc: 0.009453    time: 0.2917  last_time: 0.2777  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:45:09 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 2019  total_loss: 0.6688  loss_cls: 0.2148  loss_box_reg: 0.2815  loss_mask: 0.177  loss_rpn_cls: 0.0004817  loss_rpn_loc: 0.01012    time: 0.2920  last_time: 0.2523  data_time: 0.0013  last_data_time: 0.0009   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:45:15 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 2039  total_loss: 0.7653  loss_cls: 0.2738  loss_box_reg: 0.2596  loss_mask: 0.1725  loss_rpn_cls: 0.001269  loss_rpn_loc: 0.01157    time: 0.2922  last_time: 0.2959  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:45:21 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 2059  total_loss: 0.6652  loss_cls: 0.2151  loss_box_reg: 0.2458  loss_mask: 0.1696  loss_rpn_cls: 0.002383  loss_rpn_loc: 0.01011    time: 0.2925  last_time: 0.2631  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:45:27 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 2079  total_loss: 0.8547  loss_cls: 0.2669  loss_box_reg: 0.3102  loss_mask: 0.199  loss_rpn_cls: 0.002756  loss_rpn_loc: 0.0117    time: 0.2925  last_time: 0.3191  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:45:33 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 2099  total_loss: 0.8071  loss_cls: 0.2552  loss_box_reg: 0.3099  loss_mask: 0.2122  loss_rpn_cls: 0.004455  loss_rpn_loc: 0.01027    time: 0.2926  last_time: 0.2835  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:45:39 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 2119  total_loss: 0.7804  loss_cls: 0.2325  loss_box_reg: 0.3193  loss_mask: 0.2053  loss_rpn_cls: 0.001219  loss_rpn_loc: 0.009702    time: 0.2925  last_time: 0.3463  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:45:45 d2.utils.events]: \u001b[0m eta: 0:04:23  iter: 2139  total_loss: 0.6252  loss_cls: 0.23  loss_box_reg: 0.2281  loss_mask: 0.1583  loss_rpn_cls: 0.001182  loss_rpn_loc: 0.008957    time: 0.2927  last_time: 0.3127  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:45:51 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 2159  total_loss: 0.7307  loss_cls: 0.2532  loss_box_reg: 0.2454  loss_mask: 0.1752  loss_rpn_cls: 0.001469  loss_rpn_loc: 0.0101    time: 0.2928  last_time: 0.2818  data_time: 0.0013  last_data_time: 0.0016   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:45:57 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 2179  total_loss: 0.5778  loss_cls: 0.2219  loss_box_reg: 0.2073  loss_mask: 0.144  loss_rpn_cls: 0.001316  loss_rpn_loc: 0.008383    time: 0.2928  last_time: 0.2768  data_time: 0.0015  last_data_time: 0.0014   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:46:03 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 2199  total_loss: 0.675  loss_cls: 0.2538  loss_box_reg: 0.2626  loss_mask: 0.1952  loss_rpn_cls: 0.002296  loss_rpn_loc: 0.01054    time: 0.2930  last_time: 0.3230  data_time: 0.0015  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:46:10 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 2219  total_loss: 0.7006  loss_cls: 0.2281  loss_box_reg: 0.2698  loss_mask: 0.1903  loss_rpn_cls: 0.002028  loss_rpn_loc: 0.0102    time: 0.2931  last_time: 0.3329  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:46:16 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 2239  total_loss: 0.6753  loss_cls: 0.1907  loss_box_reg: 0.2368  loss_mask: 0.149  loss_rpn_cls: 0.002206  loss_rpn_loc: 0.01106    time: 0.2932  last_time: 0.3242  data_time: 0.0014  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:46:22 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 2259  total_loss: 0.6641  loss_cls: 0.2266  loss_box_reg: 0.2213  loss_mask: 0.1481  loss_rpn_cls: 0.0003947  loss_rpn_loc: 0.009351    time: 0.2933  last_time: 0.2652  data_time: 0.0017  last_data_time: 0.0014   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:46:28 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 2279  total_loss: 0.6146  loss_cls: 0.1894  loss_box_reg: 0.2401  loss_mask: 0.1703  loss_rpn_cls: 0.002154  loss_rpn_loc: 0.00805    time: 0.2934  last_time: 0.3017  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:46:34 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 2299  total_loss: 0.6923  loss_cls: 0.2  loss_box_reg: 0.2559  loss_mask: 0.2203  loss_rpn_cls: 0.0006466  loss_rpn_loc: 0.009641    time: 0.2935  last_time: 0.3283  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:46:40 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 2319  total_loss: 0.7445  loss_cls: 0.2532  loss_box_reg: 0.2796  loss_mask: 0.1733  loss_rpn_cls: 0.001362  loss_rpn_loc: 0.007364    time: 0.2937  last_time: 0.3237  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:46:46 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 2339  total_loss: 0.622  loss_cls: 0.2559  loss_box_reg: 0.2098  loss_mask: 0.1639  loss_rpn_cls: 0.002357  loss_rpn_loc: 0.01346    time: 0.2938  last_time: 0.2859  data_time: 0.0015  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:46:53 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 2359  total_loss: 0.7206  loss_cls: 0.2344  loss_box_reg: 0.2673  loss_mask: 0.1798  loss_rpn_cls: 0.0005604  loss_rpn_loc: 0.01233    time: 0.2939  last_time: 0.3103  data_time: 0.0014  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:46:59 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 2379  total_loss: 0.5388  loss_cls: 0.1935  loss_box_reg: 0.2737  loss_mask: 0.146  loss_rpn_cls: 0.001885  loss_rpn_loc: 0.007657    time: 0.2940  last_time: 0.2855  data_time: 0.0014  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:47:05 d2.utils.events]: \u001b[0m eta: 0:03:03  iter: 2399  total_loss: 0.6942  loss_cls: 0.2181  loss_box_reg: 0.2951  loss_mask: 0.1756  loss_rpn_cls: 0.0008279  loss_rpn_loc: 0.007881    time: 0.2940  last_time: 0.2900  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:47:11 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 2419  total_loss: 0.5518  loss_cls: 0.155  loss_box_reg: 0.2065  loss_mask: 0.1602  loss_rpn_cls: 0.001618  loss_rpn_loc: 0.007534    time: 0.2941  last_time: 0.2704  data_time: 0.0013  last_data_time: 0.0016   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:47:17 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 2439  total_loss: 0.6937  loss_cls: 0.1673  loss_box_reg: 0.2457  loss_mask: 0.1892  loss_rpn_cls: 0.001161  loss_rpn_loc: 0.01101    time: 0.2943  last_time: 0.3451  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:47:23 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 2459  total_loss: 0.531  loss_cls: 0.1781  loss_box_reg: 0.1772  loss_mask: 0.1276  loss_rpn_cls: 0.001448  loss_rpn_loc: 0.007606    time: 0.2943  last_time: 0.3268  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:47:29 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 2479  total_loss: 0.6872  loss_cls: 0.2157  loss_box_reg: 0.2783  loss_mask: 0.1502  loss_rpn_cls: 0.001341  loss_rpn_loc: 0.01345    time: 0.2943  last_time: 0.3305  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:47:35 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 2499  total_loss: 0.5682  loss_cls: 0.2102  loss_box_reg: 0.241  loss_mask: 0.1412  loss_rpn_cls: 0.0002918  loss_rpn_loc: 0.006468    time: 0.2943  last_time: 0.2921  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:47:41 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 2519  total_loss: 0.6681  loss_cls: 0.2071  loss_box_reg: 0.2639  loss_mask: 0.2041  loss_rpn_cls: 0.000945  loss_rpn_loc: 0.01014    time: 0.2943  last_time: 0.2990  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:47:47 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 2539  total_loss: 0.7247  loss_cls: 0.2271  loss_box_reg: 0.3024  loss_mask: 0.1927  loss_rpn_cls: 0.0004986  loss_rpn_loc: 0.01169    time: 0.2942  last_time: 0.2876  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:47:52 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 2559  total_loss: 0.5958  loss_cls: 0.2447  loss_box_reg: 0.2125  loss_mask: 0.1639  loss_rpn_cls: 0.001392  loss_rpn_loc: 0.01153    time: 0.2941  last_time: 0.2979  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:47:58 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 2579  total_loss: 0.5727  loss_cls: 0.1782  loss_box_reg: 0.2158  loss_mask: 0.1425  loss_rpn_cls: 0.00211  loss_rpn_loc: 0.00973    time: 0.2941  last_time: 0.2762  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:48:04 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 2599  total_loss: 0.6103  loss_cls: 0.1873  loss_box_reg: 0.1959  loss_mask: 0.1436  loss_rpn_cls: 0.001219  loss_rpn_loc: 0.008708    time: 0.2941  last_time: 0.2994  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:48:10 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 2619  total_loss: 0.7096  loss_cls: 0.2213  loss_box_reg: 0.243  loss_mask: 0.193  loss_rpn_cls: 0.0003657  loss_rpn_loc: 0.01035    time: 0.2940  last_time: 0.2537  data_time: 0.0011  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:48:15 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 2639  total_loss: 0.5444  loss_cls: 0.1739  loss_box_reg: 0.2003  loss_mask: 0.1448  loss_rpn_cls: 0.003409  loss_rpn_loc: 0.00613    time: 0.2940  last_time: 0.2355  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:48:21 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 2659  total_loss: 0.7205  loss_cls: 0.236  loss_box_reg: 0.2963  loss_mask: 0.172  loss_rpn_cls: 0.001217  loss_rpn_loc: 0.01005    time: 0.2940  last_time: 0.3177  data_time: 0.0011  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:48:27 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 2679  total_loss: 0.7751  loss_cls: 0.2569  loss_box_reg: 0.2657  loss_mask: 0.2052  loss_rpn_cls: 0.002443  loss_rpn_loc: 0.01704    time: 0.2939  last_time: 0.2561  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:48:33 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 2699  total_loss: 0.643  loss_cls: 0.2435  loss_box_reg: 0.2012  loss_mask: 0.1613  loss_rpn_cls: 0.0013  loss_rpn_loc: 0.009725    time: 0.2939  last_time: 0.2564  data_time: 0.0011  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:48:39 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 2719  total_loss: 0.6843  loss_cls: 0.2326  loss_box_reg: 0.2466  loss_mask: 0.1578  loss_rpn_cls: 0.00428  loss_rpn_loc: 0.006956    time: 0.2939  last_time: 0.3327  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:48:45 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2739  total_loss: 0.6257  loss_cls: 0.1864  loss_box_reg: 0.2217  loss_mask: 0.1433  loss_rpn_cls: 0.001098  loss_rpn_loc: 0.008289    time: 0.2940  last_time: 0.3073  data_time: 0.0014  last_data_time: 0.0009   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:48:51 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 2759  total_loss: 0.506  loss_cls: 0.1536  loss_box_reg: 0.2355  loss_mask: 0.1462  loss_rpn_cls: 0.000637  loss_rpn_loc: 0.008812    time: 0.2940  last_time: 0.3012  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:48:57 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 2779  total_loss: 0.6494  loss_cls: 0.1679  loss_box_reg: 0.2694  loss_mask: 0.1465  loss_rpn_cls: 0.0002944  loss_rpn_loc: 0.007571    time: 0.2940  last_time: 0.3023  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:49:03 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 2799  total_loss: 0.6709  loss_cls: 0.2062  loss_box_reg: 0.2559  loss_mask: 0.1773  loss_rpn_cls: 0.002553  loss_rpn_loc: 0.007137    time: 0.2941  last_time: 0.3272  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:49:09 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 2819  total_loss: 0.5628  loss_cls: 0.143  loss_box_reg: 0.2177  loss_mask: 0.1891  loss_rpn_cls: 0.002039  loss_rpn_loc: 0.006899    time: 0.2942  last_time: 0.3146  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:49:15 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 2839  total_loss: 0.6312  loss_cls: 0.1899  loss_box_reg: 0.2181  loss_mask: 0.1567  loss_rpn_cls: 0.0009815  loss_rpn_loc: 0.01433    time: 0.2942  last_time: 0.3245  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:49:21 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 2859  total_loss: 0.5767  loss_cls: 0.224  loss_box_reg: 0.1911  loss_mask: 0.1465  loss_rpn_cls: 0.001096  loss_rpn_loc: 0.009749    time: 0.2943  last_time: 0.3688  data_time: 0.0013  last_data_time: 0.0021   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:49:27 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 2879  total_loss: 0.5799  loss_cls: 0.2274  loss_box_reg: 0.2027  loss_mask: 0.1379  loss_rpn_cls: 0.001007  loss_rpn_loc: 0.007685    time: 0.2943  last_time: 0.2889  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:49:33 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 2899  total_loss: 0.7007  loss_cls: 0.1847  loss_box_reg: 0.2592  loss_mask: 0.1727  loss_rpn_cls: 0.0008269  loss_rpn_loc: 0.009459    time: 0.2943  last_time: 0.3322  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:49:39 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 2919  total_loss: 0.5189  loss_cls: 0.1616  loss_box_reg: 0.1964  loss_mask: 0.1271  loss_rpn_cls: 0.00157  loss_rpn_loc: 0.004949    time: 0.2944  last_time: 0.2954  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:49:45 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 2939  total_loss: 0.7303  loss_cls: 0.2357  loss_box_reg: 0.2798  loss_mask: 0.1835  loss_rpn_cls: 0.002725  loss_rpn_loc: 0.009267    time: 0.2944  last_time: 0.2836  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:49:51 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 2959  total_loss: 0.6029  loss_cls: 0.1956  loss_box_reg: 0.2466  loss_mask: 0.1654  loss_rpn_cls: 0.003175  loss_rpn_loc: 0.008812    time: 0.2944  last_time: 0.2946  data_time: 0.0011  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:49:57 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 2979  total_loss: 0.5777  loss_cls: 0.1769  loss_box_reg: 0.2138  loss_mask: 0.1548  loss_rpn_cls: 0.001361  loss_rpn_loc: 0.008043    time: 0.2945  last_time: 0.3151  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:50:06 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2999  total_loss: 0.6589  loss_cls: 0.1534  loss_box_reg: 0.2254  loss_mask: 0.189  loss_rpn_cls: 0.0008528  loss_rpn_loc: 0.009452    time: 0.2945  last_time: 0.3041  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00025  max_mem: 1591M\n",
      "\u001b[32m[05/12 17:50:06 d2.engine.hooks]: \u001b[0mOverall training speed: 2998 iterations in 0:14:42 (0.2945 s / it)\n",
      "\u001b[32m[05/12 17:50:06 d2.engine.hooks]: \u001b[0mTotal training time: 0:14:47 (0:00:04 on hooks)\n",
      "\u001b[32m[05/12 17:50:06 d2.data.datasets.coco]: \u001b[0mLoaded 300 images in COCO format from dataset/annotation/valid_annotations.json\n",
      "\u001b[32m[05/12 17:50:06 d2.data.build]: \u001b[0mDistribution of instances among all 15 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Whole Chicken | 22           | Chicken Bre.. | 50           | Chicken Wings | 125          |\n",
      "|  Chicken Leg  | 92           | Chicken Thigh | 104          |      Egg      | 80           |\n",
      "|     Tofu      | 45           |   Lean Pork   | 58           |   Lean Beef   | 21           |\n",
      "| Sweet Potato  | 74           |   Potatoes    | 26           |     Rice      | 22           |\n",
      "| Whole Wheat.. | 50           |  White Bread  | 59           |   Broccoli    | 38           |\n",
      "|               |              |               |              |               |              |\n",
      "|     total     | 866          |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[05/12 17:50:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[05/12 17:50:06 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[05/12 17:50:06 d2.data.common]: \u001b[0mSerializing 300 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/12 17:50:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/12 17:50:06 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/14 09:27:37 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./outputR50\\model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import cv2\n",
    "import os\n",
    "import ctypes\n",
    "import torch\n",
    "from detectron2.structures import Instances\n",
    "\n",
    "# Detect screen size (Windows)\n",
    "user32 = ctypes.windll.user32\n",
    "screen_width = user32.GetSystemMetrics(0)\n",
    "screen_height = user32.GetSystemMetrics(1)\n",
    "\n",
    "# Define class labels\n",
    "class_names = [\n",
    "    \"Whole Chicken\",\n",
    "    \"Chicken Breast\",\n",
    "    \"Chicken Wings\",\n",
    "    \"Chicken Leg\",\n",
    "    \"Chicken Thigh\",\n",
    "    \"Egg\",\n",
    "    \"Tofu\",\n",
    "    \"Lean Pork\",\n",
    "    \"Lean Beef\",\n",
    "    \"Sweet Potato\",\n",
    "    \"Potatoes\",\n",
    "    \"Rice\",\n",
    "    \"Whole Wheat Bread\",\n",
    "    \"White Bread\",\n",
    "    \"Brocolli\"\n",
    "]\n",
    "MetadataCatalog.get(\"food_train\").thing_classes = class_names\n",
    "\n",
    "# Use GPU and set model weights\n",
    "cfg.MODEL.DEVICE = \"cuda\"\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Load image\n",
    "image_path = \"dataset/test/whole-chicken.jpg\"\n",
    "im = cv2.imread(image_path)\n",
    "if im is None:\n",
    "    raise FileNotFoundError(f\"Image not found at path: {image_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHOWS THE HIGHEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\Desktop\\Thesis\\foodenv312\\Lib\\site-packages\\torch\\functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4316.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Prediction: Whole Chicken (93.79%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run prediction\n",
    "outputs = predictor(im)\n",
    "instances = outputs[\"instances\"]\n",
    "\n",
    "# Get top prediction\n",
    "if len(instances) > 0:\n",
    "    top_idx = torch.argmax(instances.scores)\n",
    "\n",
    "    # Create a new Instances object containing only the top prediction\n",
    "    top_instances = Instances(instances.image_size)\n",
    "    for field in instances.get_fields():\n",
    "        top_instances.set(field, instances.get(field)[top_idx:top_idx+1])\n",
    "\n",
    "    # Visualize\n",
    "    metadata = MetadataCatalog.get(\"food_train\")\n",
    "    v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=1.2)\n",
    "    out = v.draw_instance_predictions(top_instances.to(\"cpu\"))\n",
    "    output_image = out.get_image()[:, :, ::-1]\n",
    "\n",
    "    # Resize to fit screen\n",
    "    h, w = output_image.shape[:2]\n",
    "    scale = min(screen_width / w, screen_height / h)\n",
    "    resized_image = cv2.resize(output_image, (int(w * scale), int(h * scale)))\n",
    "\n",
    "    # Display\n",
    "    predicted_class = instances.pred_classes[top_idx].item()\n",
    "    confidence = instances.scores[top_idx].item()\n",
    "    print(f\"Top Prediction: {class_names[predicted_class]} ({confidence*100:.2f}%)\")\n",
    "\n",
    "    cv2.imshow(\"Top Prediction\", resized_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No predictions found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHOWS 60% or higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction\n",
    "outputs = predictor(im)\n",
    "instances = outputs[\"instances\"]\n",
    "\n",
    "\n",
    "threshold = 0.60\n",
    "keep = instances.scores >= threshold\n",
    "filtered_instances = instances[keep]\n",
    "\n",
    "# Load metadata\n",
    "metadata = MetadataCatalog.get(\"food_train\")\n",
    "\n",
    "# Visualization\n",
    "v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=1.2)\n",
    "out = v.draw_instance_predictions(filtered_instances.to(\"cpu\"))\n",
    "output_image = out.get_image()[:, :, ::-1]\n",
    "\n",
    "# Resize to fit screen\n",
    "h, w = output_image.shape[:2]\n",
    "scale_w = screen_width / w\n",
    "scale_h = screen_height / h\n",
    "scale = min(scale_w, scale_h)\n",
    "resized_image = cv2.resize(output_image, (int(w * scale), int(h * scale)))\n",
    "\n",
    "# Show the image\n",
    "cv2.imshow(\"Prediction\", resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/14 09:15:15 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[05/14 09:15:15 d2.data.datasets.coco]: \u001b[0mLoaded 300 images in COCO format from dataset/annotation/valid_annotations.json\n",
      "\u001b[32m[05/14 09:15:15 d2.data.build]: \u001b[0mDistribution of instances among all 15 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Whole Chicken | 22           | Chicken Bre.. | 50           | Chicken Wings | 125          |\n",
      "|  Chicken Leg  | 92           | Chicken Thigh | 104          |      Egg      | 80           |\n",
      "|     Tofu      | 45           |   Lean Pork   | 58           |   Lean Beef   | 21           |\n",
      "| Sweet Potato  | 74           |   Potatoes    | 26           |     Rice      | 22           |\n",
      "| Whole Wheat.. | 50           |  White Bread  | 59           |   Broccoli    | 38           |\n",
      "|               |              |               |              |               |              |\n",
      "|     total     | 866          |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[05/14 09:15:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[05/14 09:15:15 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[05/14 09:15:15 d2.data.common]: \u001b[0mSerializing 300 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/14 09:15:15 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[32m[05/14 09:15:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 batches\n",
      "\u001b[32m[05/14 09:15:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. Dataloading: 0.0005 s/iter. Inference: 0.0746 s/iter. Eval: 0.0065 s/iter. Total: 0.0816 s/iter. ETA=0:00:23\n",
      "\u001b[32m[05/14 09:15:26 d2.evaluation.evaluator]: \u001b[0mInference done 63/300. Dataloading: 0.0006 s/iter. Inference: 0.0773 s/iter. Eval: 0.0172 s/iter. Total: 0.0953 s/iter. ETA=0:00:22\n",
      "\u001b[32m[05/14 09:15:31 d2.evaluation.evaluator]: \u001b[0mInference done 120/300. Dataloading: 0.0006 s/iter. Inference: 0.0736 s/iter. Eval: 0.0173 s/iter. Total: 0.0916 s/iter. ETA=0:00:16\n",
      "\u001b[32m[05/14 09:15:36 d2.evaluation.evaluator]: \u001b[0mInference done 182/300. Dataloading: 0.0006 s/iter. Inference: 0.0715 s/iter. Eval: 0.0157 s/iter. Total: 0.0879 s/iter. ETA=0:00:10\n",
      "\u001b[32m[05/14 09:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 246/300. Dataloading: 0.0006 s/iter. Inference: 0.0704 s/iter. Eval: 0.0145 s/iter. Total: 0.0855 s/iter. ETA=0:00:04\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.800287 (0.087459 s / iter per device, on 1 devices)\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.069955 s / iter per device, on 1 devices)\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.07 seconds.\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.665\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.492\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.633\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.663\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 44.149 | 66.543 | 49.203 |  nan  | 26.984 | 45.738 |\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category          | AP     | category       | AP     | category      | AP     |\n",
      "|:------------------|:-------|:---------------|:-------|:--------------|:-------|\n",
      "| Whole Chicken     | 45.868 | Chicken Breast | 47.993 | Chicken Wings | 17.702 |\n",
      "| Chicken Leg       | 37.741 | Chicken Thigh  | 47.923 | Egg           | 49.328 |\n",
      "| Tofu              | 19.490 | Lean Pork      | 34.525 | Lean Beef     | 55.433 |\n",
      "| Sweet Potato      | 52.683 | Potatoes       | 47.021 | Rice          | 74.415 |\n",
      "| Whole Wheat Bread | 42.826 | White Bread    | 42.807 | Broccoli      | 46.472 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.650\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.494\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.455\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.632\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 43.573 | 64.989 | 49.414 |  nan  | 19.216 | 45.455 |\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[05/14 09:15:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category          | AP     | category       | AP     | category      | AP     |\n",
      "|:------------------|:-------|:---------------|:-------|:--------------|:-------|\n",
      "| Whole Chicken     | 42.002 | Chicken Breast | 49.171 | Chicken Wings | 14.110 |\n",
      "| Chicken Leg       | 34.684 | Chicken Thigh  | 48.832 | Egg           | 52.062 |\n",
      "| Tofu              | 22.391 | Lean Pork      | 36.063 | Lean Beef     | 58.778 |\n",
      "| Sweet Potato      | 47.174 | Potatoes       | 47.123 | Rice          | 78.424 |\n",
      "| Whole Wheat Bread | 37.750 | White Bread    | 40.978 | Broccoli      | 44.057 |\n",
      "OrderedDict({'bbox': {'AP': 44.14855354264379, 'AP50': 66.54274460508834, 'AP75': 49.20260633963468, 'APs': nan, 'APm': 26.983715869058127, 'APl': 45.73775929553892, 'AP-Whole Chicken': 45.86822492289595, 'AP-Chicken Breast': 47.99309754252897, 'AP-Chicken Wings': 17.701871204920376, 'AP-Chicken Leg': 37.741060502450196, 'AP-Chicken Thigh': 47.92325783243444, 'AP-Egg': 49.32831857883549, 'AP-Tofu': 19.490204300711834, 'AP-Lean Pork': 34.52549513452022, 'AP-Lean Beef': 55.433240851557684, 'AP-Sweet Potato': 52.682786013747275, 'AP-Potatoes': 47.02117732781681, 'AP-Rice': 74.41478769725713, 'AP-Whole Wheat Bread': 42.825853741226645, 'AP-White Bread': 42.80654455682279, 'AP-Broccoli': 46.472382931931}, 'segm': {'AP': 43.57328813180491, 'AP50': 64.98919746354083, 'AP75': 49.41422662128464, 'APs': nan, 'APm': 19.215803169974965, 'APl': 45.454613175031724, 'AP-Whole Chicken': 42.0019537577352, 'AP-Chicken Breast': 49.171383150487564, 'AP-Chicken Wings': 14.110056509930782, 'AP-Chicken Leg': 34.68388271451134, 'AP-Chicken Thigh': 48.8320752879549, 'AP-Egg': 52.06167862606833, 'AP-Tofu': 22.391169949664512, 'AP-Lean Pork': 36.06308247462513, 'AP-Lean Beef': 58.778125752135644, 'AP-Sweet Potato': 47.17385646045548, 'AP-Potatoes': 47.123210409276226, 'AP-Rice': 78.42396687700615, 'AP-Whole Wheat Bread': 37.750319610636964, 'AP-White Bread': 40.9780287161277, 'AP-Broccoli': 44.05653168045759}})\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# Use your dataset name (registered during training/validation)\n",
    "evaluator = COCOEvaluator(\"food_val\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"food_val\")\n",
    "\n",
    "# Run evaluation\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foodenv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
