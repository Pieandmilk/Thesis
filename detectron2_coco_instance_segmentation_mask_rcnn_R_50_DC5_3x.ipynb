{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef612f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8\n",
      "Detectron2 is working!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "print(torch.version.cuda)\n",
    "setup_logger()\n",
    "print(\"Detectron2 is working!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43bcdcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# Unregister the dataset if it's already registered\n",
    "for d in [\"food_train\", \"food_val\"]:\n",
    "    if d in DatasetCatalog.list():\n",
    "        DatasetCatalog.remove(d)\n",
    "        MetadataCatalog.remove(d)\n",
    "\n",
    "# Now register again with correct paths\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(\"food_train\", {}, r\"dataset/annotation/train_annotation.json\", \"dataset/train\")\n",
    "register_coco_instances(\"food_val\", {}, r\"dataset/annotation/valid_annotations.json\", \"dataset/valid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b62cc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "import os\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_1x.yaml\"))  # change here\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_1x.yaml\")\n",
    "cfg.DATASETS.TRAIN = (\"food_train\",)\n",
    "cfg.DATASETS.TEST = (\"food_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 3000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 15  # your number of food classes\n",
    "\n",
    "cfg.OUTPUT_DIR = \"./output_R50_DC5\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8180d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/14 10:37:40 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(2048, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(2048, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=100352, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=16, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=60, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[05/14 10:37:41 d2.data.datasets.coco]: \u001b[0mLoaded 1200 images in COCO format from dataset/annotation/train_annotation.json\n",
      "\u001b[32m[05/14 10:37:41 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1200 images left.\n",
      "\u001b[32m[05/14 10:37:41 d2.data.build]: \u001b[0mDistribution of instances among all 15 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Whole Chicken | 81           | Chicken Bre.. | 202          | Chicken Wings | 399          |\n",
      "|  Chicken Leg  | 395          | Chicken Thigh | 366          |      Egg      | 177          |\n",
      "|     Tofu      | 120          |   Lean Pork   | 216          |   Lean Beef   | 89           |\n",
      "| Sweet Potato  | 256          |   Potatoes    | 97           |     Rice      | 83           |\n",
      "| Whole Wheat.. | 192          |  White Bread  | 227          |   Broccolli   | 162          |\n",
      "|               |              |               |              |               |              |\n",
      "|     total     | 3062         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[05/14 10:37:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[05/14 10:37:41 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[05/14 10:37:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[05/14 10:37:41 d2.data.common]: \u001b[0mSerializing 1200 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/14 10:37:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.40 MiB\n",
      "\u001b[32m[05/14 10:37:41 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/14 10:37:41 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[05/14 10:37:41 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_1x/137260150/model_final_4f86c3.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (60, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (60,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (15, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/14 10:37:41 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\Desktop\\Thesis\\foodenv312\\Lib\\site-packages\\torch\\functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4316.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/14 10:37:57 d2.utils.events]: \u001b[0m eta: 0:22:25  iter: 19  total_loss: 4.325  loss_cls: 2.683  loss_box_reg: 0.7886  loss_mask: 0.6918  loss_rpn_cls: 0.1082  loss_rpn_loc: 0.1195    time: 0.4836  last_time: 0.4172  data_time: 0.2573  last_data_time: 0.0010   lr: 4.9953e-06  max_mem: 4110M\n",
      "\u001b[32m[05/14 10:38:07 d2.utils.events]: \u001b[0m eta: 0:22:15  iter: 39  total_loss: 4.081  loss_cls: 2.543  loss_box_reg: 0.6535  loss_mask: 0.6907  loss_rpn_cls: 0.06802  loss_rpn_loc: 0.1042    time: 0.4823  last_time: 0.4145  data_time: 0.0012  last_data_time: 0.0014   lr: 9.9902e-06  max_mem: 4110M\n",
      "\u001b[32m[05/14 10:38:16 d2.utils.events]: \u001b[0m eta: 0:22:05  iter: 59  total_loss: 4.107  loss_cls: 2.263  loss_box_reg: 0.7486  loss_mask: 0.6883  loss_rpn_cls: 0.08375  loss_rpn_loc: 0.106    time: 0.4779  last_time: 0.3780  data_time: 0.0011  last_data_time: 0.0009   lr: 1.4985e-05  max_mem: 4110M\n",
      "\u001b[32m[05/14 10:38:25 d2.utils.events]: \u001b[0m eta: 0:21:44  iter: 79  total_loss: 3.478  loss_cls: 1.799  loss_box_reg: 0.8033  loss_mask: 0.6852  loss_rpn_cls: 0.08908  loss_rpn_loc: 0.07575    time: 0.4708  last_time: 0.5467  data_time: 0.0012  last_data_time: 0.0013   lr: 1.998e-05  max_mem: 4110M\n",
      "\u001b[32m[05/14 10:38:34 d2.utils.events]: \u001b[0m eta: 0:21:29  iter: 99  total_loss: 3.035  loss_cls: 1.361  loss_box_reg: 0.7537  loss_mask: 0.6839  loss_rpn_cls: 0.07192  loss_rpn_loc: 0.1044    time: 0.4691  last_time: 0.3984  data_time: 0.0012  last_data_time: 0.0010   lr: 2.4975e-05  max_mem: 4111M\n",
      "\u001b[32m[05/14 10:38:44 d2.utils.events]: \u001b[0m eta: 0:21:19  iter: 119  total_loss: 2.821  loss_cls: 1.124  loss_box_reg: 0.8711  loss_mask: 0.678  loss_rpn_cls: 0.0901  loss_rpn_loc: 0.09227    time: 0.4699  last_time: 0.5455  data_time: 0.0012  last_data_time: 0.0012   lr: 2.997e-05  max_mem: 4111M\n",
      "\u001b[32m[05/14 10:38:53 d2.utils.events]: \u001b[0m eta: 0:21:09  iter: 139  total_loss: 2.471  loss_cls: 0.8676  loss_box_reg: 0.7402  loss_mask: 0.6706  loss_rpn_cls: 0.06763  loss_rpn_loc: 0.1028    time: 0.4677  last_time: 0.5705  data_time: 0.0013  last_data_time: 0.0011   lr: 3.4965e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:39:03 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 159  total_loss: 2.655  loss_cls: 0.9085  loss_box_reg: 0.8463  loss_mask: 0.6697  loss_rpn_cls: 0.07121  loss_rpn_loc: 0.1023    time: 0.4696  last_time: 0.5862  data_time: 0.0012  last_data_time: 0.0011   lr: 3.996e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:39:12 d2.utils.events]: \u001b[0m eta: 0:21:06  iter: 179  total_loss: 2.401  loss_cls: 0.7936  loss_box_reg: 0.7523  loss_mask: 0.6602  loss_rpn_cls: 0.06411  loss_rpn_loc: 0.09893    time: 0.4718  last_time: 0.5434  data_time: 0.0011  last_data_time: 0.0011   lr: 4.4955e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:39:22 d2.utils.events]: \u001b[0m eta: 0:20:59  iter: 199  total_loss: 2.361  loss_cls: 0.7939  loss_box_reg: 0.7515  loss_mask: 0.6493  loss_rpn_cls: 0.06648  loss_rpn_loc: 0.07817    time: 0.4736  last_time: 0.6211  data_time: 0.0012  last_data_time: 0.0011   lr: 4.995e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:39:32 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 219  total_loss: 2.515  loss_cls: 0.8695  loss_box_reg: 0.8372  loss_mask: 0.645  loss_rpn_cls: 0.07198  loss_rpn_loc: 0.08441    time: 0.4746  last_time: 0.5647  data_time: 0.0014  last_data_time: 0.0018   lr: 5.4945e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:39:41 d2.utils.events]: \u001b[0m eta: 0:20:37  iter: 239  total_loss: 2.418  loss_cls: 0.7879  loss_box_reg: 0.8323  loss_mask: 0.6346  loss_rpn_cls: 0.04972  loss_rpn_loc: 0.08876    time: 0.4745  last_time: 0.5479  data_time: 0.0012  last_data_time: 0.0013   lr: 5.994e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:39:50 d2.utils.events]: \u001b[0m eta: 0:20:26  iter: 259  total_loss: 2.466  loss_cls: 0.8116  loss_box_reg: 0.8035  loss_mask: 0.6193  loss_rpn_cls: 0.06257  loss_rpn_loc: 0.08922    time: 0.4733  last_time: 0.4197  data_time: 0.0012  last_data_time: 0.0011   lr: 6.4935e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:40:00 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 279  total_loss: 2.443  loss_cls: 0.7707  loss_box_reg: 0.8436  loss_mask: 0.5996  loss_rpn_cls: 0.06767  loss_rpn_loc: 0.1092    time: 0.4742  last_time: 0.5513  data_time: 0.0012  last_data_time: 0.0010   lr: 6.993e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:40:10 d2.utils.events]: \u001b[0m eta: 0:20:08  iter: 299  total_loss: 2.345  loss_cls: 0.754  loss_box_reg: 0.811  loss_mask: 0.5805  loss_rpn_cls: 0.05862  loss_rpn_loc: 0.07895    time: 0.4749  last_time: 0.5899  data_time: 0.0011  last_data_time: 0.0009   lr: 7.4925e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:40:20 d2.utils.events]: \u001b[0m eta: 0:19:59  iter: 319  total_loss: 2.322  loss_cls: 0.762  loss_box_reg: 0.8162  loss_mask: 0.5703  loss_rpn_cls: 0.06523  loss_rpn_loc: 0.0965    time: 0.4758  last_time: 0.4230  data_time: 0.0011  last_data_time: 0.0013   lr: 7.992e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:40:29 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 339  total_loss: 2.25  loss_cls: 0.7219  loss_box_reg: 0.7969  loss_mask: 0.5758  loss_rpn_cls: 0.07307  loss_rpn_loc: 0.09899    time: 0.4759  last_time: 0.4321  data_time: 0.0013  last_data_time: 0.0015   lr: 8.4915e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:40:39 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 359  total_loss: 2.248  loss_cls: 0.7288  loss_box_reg: 0.8363  loss_mask: 0.5203  loss_rpn_cls: 0.0502  loss_rpn_loc: 0.07688    time: 0.4764  last_time: 0.4154  data_time: 0.0013  last_data_time: 0.0011   lr: 8.991e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:40:49 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 379  total_loss: 2.104  loss_cls: 0.689  loss_box_reg: 0.8044  loss_mask: 0.4948  loss_rpn_cls: 0.04602  loss_rpn_loc: 0.09357    time: 0.4766  last_time: 0.6098  data_time: 0.0013  last_data_time: 0.0020   lr: 9.4905e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:40:58 d2.utils.events]: \u001b[0m eta: 0:19:30  iter: 399  total_loss: 2.168  loss_cls: 0.7037  loss_box_reg: 0.7892  loss_mask: 0.5015  loss_rpn_cls: 0.0812  loss_rpn_loc: 0.08617    time: 0.4775  last_time: 0.5261  data_time: 0.0014  last_data_time: 0.0011   lr: 9.99e-05  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:41:08 d2.utils.events]: \u001b[0m eta: 0:19:17  iter: 419  total_loss: 2.222  loss_cls: 0.7626  loss_box_reg: 0.8293  loss_mask: 0.4892  loss_rpn_cls: 0.07603  loss_rpn_loc: 0.09565    time: 0.4766  last_time: 0.4449  data_time: 0.0013  last_data_time: 0.0009   lr: 0.0001049  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:41:17 d2.utils.events]: \u001b[0m eta: 0:19:13  iter: 439  total_loss: 2.163  loss_cls: 0.6763  loss_box_reg: 0.7954  loss_mask: 0.4474  loss_rpn_cls: 0.0543  loss_rpn_loc: 0.08014    time: 0.4766  last_time: 0.4744  data_time: 0.0011  last_data_time: 0.0009   lr: 0.00010989  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:41:27 d2.utils.events]: \u001b[0m eta: 0:19:06  iter: 459  total_loss: 1.988  loss_cls: 0.6563  loss_box_reg: 0.7862  loss_mask: 0.4298  loss_rpn_cls: 0.05235  loss_rpn_loc: 0.08155    time: 0.4771  last_time: 0.5751  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00011489  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:41:37 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 479  total_loss: 1.912  loss_cls: 0.6363  loss_box_reg: 0.7145  loss_mask: 0.4146  loss_rpn_cls: 0.05243  loss_rpn_loc: 0.09083    time: 0.4771  last_time: 0.4535  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00011988  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:41:46 d2.utils.events]: \u001b[0m eta: 0:18:48  iter: 499  total_loss: 2.001  loss_cls: 0.6457  loss_box_reg: 0.7671  loss_mask: 0.4401  loss_rpn_cls: 0.0633  loss_rpn_loc: 0.0893    time: 0.4772  last_time: 0.4081  data_time: 0.0011  last_data_time: 0.0011   lr: 0.00012488  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:41:55 d2.utils.events]: \u001b[0m eta: 0:18:38  iter: 519  total_loss: 2  loss_cls: 0.6861  loss_box_reg: 0.773  loss_mask: 0.3752  loss_rpn_cls: 0.06482  loss_rpn_loc: 0.08651    time: 0.4760  last_time: 0.5855  data_time: 0.0011  last_data_time: 0.0010   lr: 0.00012987  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:42:05 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 539  total_loss: 1.945  loss_cls: 0.6455  loss_box_reg: 0.8029  loss_mask: 0.3377  loss_rpn_cls: 0.04947  loss_rpn_loc: 0.07461    time: 0.4759  last_time: 0.4378  data_time: 0.0011  last_data_time: 0.0014   lr: 0.00013487  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:42:14 d2.utils.events]: \u001b[0m eta: 0:18:20  iter: 559  total_loss: 1.914  loss_cls: 0.6565  loss_box_reg: 0.7747  loss_mask: 0.3109  loss_rpn_cls: 0.03548  loss_rpn_loc: 0.09389    time: 0.4761  last_time: 0.5630  data_time: 0.0011  last_data_time: 0.0009   lr: 0.00013986  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:42:24 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 579  total_loss: 1.857  loss_cls: 0.6417  loss_box_reg: 0.7529  loss_mask: 0.2729  loss_rpn_cls: 0.05224  loss_rpn_loc: 0.09055    time: 0.4767  last_time: 0.5641  data_time: 0.0011  last_data_time: 0.0012   lr: 0.00014486  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:42:33 d2.utils.events]: \u001b[0m eta: 0:18:03  iter: 599  total_loss: 1.803  loss_cls: 0.5755  loss_box_reg: 0.6584  loss_mask: 0.2815  loss_rpn_cls: 0.05255  loss_rpn_loc: 0.07683    time: 0.4766  last_time: 0.5618  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00014985  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:42:43 d2.utils.events]: \u001b[0m eta: 0:17:54  iter: 619  total_loss: 1.636  loss_cls: 0.5988  loss_box_reg: 0.666  loss_mask: 0.261  loss_rpn_cls: 0.04494  loss_rpn_loc: 0.08284    time: 0.4766  last_time: 0.4665  data_time: 0.0011  last_data_time: 0.0010   lr: 0.00015485  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:42:53 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 639  total_loss: 1.474  loss_cls: 0.497  loss_box_reg: 0.6081  loss_mask: 0.2495  loss_rpn_cls: 0.03767  loss_rpn_loc: 0.09446    time: 0.4769  last_time: 0.5528  data_time: 0.0011  last_data_time: 0.0013   lr: 0.00015984  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:43:03 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 659  total_loss: 1.535  loss_cls: 0.5903  loss_box_reg: 0.6558  loss_mask: 0.2226  loss_rpn_cls: 0.04903  loss_rpn_loc: 0.08082    time: 0.4775  last_time: 0.5844  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00016484  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:43:13 d2.utils.events]: \u001b[0m eta: 0:17:30  iter: 679  total_loss: 1.563  loss_cls: 0.5803  loss_box_reg: 0.6235  loss_mask: 0.2685  loss_rpn_cls: 0.02658  loss_rpn_loc: 0.08836    time: 0.4780  last_time: 0.4613  data_time: 0.0013  last_data_time: 0.0017   lr: 0.00016983  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:43:23 d2.utils.events]: \u001b[0m eta: 0:17:23  iter: 699  total_loss: 1.701  loss_cls: 0.6283  loss_box_reg: 0.5992  loss_mask: 0.236  loss_rpn_cls: 0.05256  loss_rpn_loc: 0.101    time: 0.4786  last_time: 0.4594  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00017483  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:43:32 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 719  total_loss: 1.36  loss_cls: 0.5249  loss_box_reg: 0.5031  loss_mask: 0.2268  loss_rpn_cls: 0.04526  loss_rpn_loc: 0.0824    time: 0.4786  last_time: 0.6291  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00017982  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:43:42 d2.utils.events]: \u001b[0m eta: 0:17:05  iter: 739  total_loss: 1.205  loss_cls: 0.4751  loss_box_reg: 0.4456  loss_mask: 0.1953  loss_rpn_cls: 0.05066  loss_rpn_loc: 0.06857    time: 0.4783  last_time: 0.5589  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00018482  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:43:51 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 759  total_loss: 1.269  loss_cls: 0.4457  loss_box_reg: 0.4462  loss_mask: 0.23  loss_rpn_cls: 0.05594  loss_rpn_loc: 0.0892    time: 0.4782  last_time: 0.4789  data_time: 0.0012  last_data_time: 0.0017   lr: 0.00018981  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:44:01 d2.utils.events]: \u001b[0m eta: 0:16:46  iter: 779  total_loss: 1.046  loss_cls: 0.3986  loss_box_reg: 0.3766  loss_mask: 0.1905  loss_rpn_cls: 0.03365  loss_rpn_loc: 0.0778    time: 0.4786  last_time: 0.4473  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00019481  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:44:11 d2.utils.events]: \u001b[0m eta: 0:16:38  iter: 799  total_loss: 1.662  loss_cls: 0.5218  loss_box_reg: 0.4855  loss_mask: 0.2934  loss_rpn_cls: 0.06911  loss_rpn_loc: 0.09041    time: 0.4787  last_time: 0.4497  data_time: 0.0013  last_data_time: 0.0012   lr: 0.0001998  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:44:20 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 819  total_loss: 1.317  loss_cls: 0.4778  loss_box_reg: 0.4525  loss_mask: 0.2576  loss_rpn_cls: 0.06043  loss_rpn_loc: 0.07537    time: 0.4786  last_time: 0.5872  data_time: 0.0013  last_data_time: 0.0016   lr: 0.0002048  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:44:30 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 839  total_loss: 1.27  loss_cls: 0.4917  loss_box_reg: 0.3766  loss_mask: 0.2194  loss_rpn_cls: 0.0582  loss_rpn_loc: 0.08626    time: 0.4788  last_time: 0.4594  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00020979  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:44:39 d2.utils.events]: \u001b[0m eta: 0:16:12  iter: 859  total_loss: 1.173  loss_cls: 0.4847  loss_box_reg: 0.4004  loss_mask: 0.2006  loss_rpn_cls: 0.05028  loss_rpn_loc: 0.07974    time: 0.4785  last_time: 0.4845  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00021479  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:44:49 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 879  total_loss: 1.221  loss_cls: 0.4316  loss_box_reg: 0.4261  loss_mask: 0.2288  loss_rpn_cls: 0.04243  loss_rpn_loc: 0.07137    time: 0.4786  last_time: 0.4420  data_time: 0.0011  last_data_time: 0.0009   lr: 0.00021978  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:44:58 d2.utils.events]: \u001b[0m eta: 0:15:54  iter: 899  total_loss: 1.089  loss_cls: 0.375  loss_box_reg: 0.3657  loss_mask: 0.2237  loss_rpn_cls: 0.04441  loss_rpn_loc: 0.0848    time: 0.4785  last_time: 0.3919  data_time: 0.0011  last_data_time: 0.0010   lr: 0.00022478  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:45:08 d2.utils.events]: \u001b[0m eta: 0:15:45  iter: 919  total_loss: 0.8472  loss_cls: 0.3474  loss_box_reg: 0.2995  loss_mask: 0.2018  loss_rpn_cls: 0.03474  loss_rpn_loc: 0.06866    time: 0.4787  last_time: 0.4563  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00022977  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:45:17 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 939  total_loss: 1.19  loss_cls: 0.479  loss_box_reg: 0.3936  loss_mask: 0.2082  loss_rpn_cls: 0.04608  loss_rpn_loc: 0.08979    time: 0.4783  last_time: 0.3668  data_time: 0.0011  last_data_time: 0.0015   lr: 0.00023477  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:45:27 d2.utils.events]: \u001b[0m eta: 0:15:27  iter: 959  total_loss: 1.134  loss_cls: 0.4452  loss_box_reg: 0.3248  loss_mask: 0.2111  loss_rpn_cls: 0.03864  loss_rpn_loc: 0.06899    time: 0.4784  last_time: 0.4426  data_time: 0.0011  last_data_time: 0.0011   lr: 0.00023976  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:45:37 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 979  total_loss: 0.956  loss_cls: 0.3096  loss_box_reg: 0.3577  loss_mask: 0.215  loss_rpn_cls: 0.02643  loss_rpn_loc: 0.08144    time: 0.4786  last_time: 0.4221  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00024476  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:45:47 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 999  total_loss: 1.071  loss_cls: 0.3742  loss_box_reg: 0.3531  loss_mask: 0.1878  loss_rpn_cls: 0.0487  loss_rpn_loc: 0.09183    time: 0.4790  last_time: 0.5792  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00024975  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:45:56 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 1019  total_loss: 1.16  loss_cls: 0.3642  loss_box_reg: 0.3747  loss_mask: 0.2662  loss_rpn_cls: 0.04481  loss_rpn_loc: 0.09975    time: 0.4786  last_time: 0.5451  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:46:06 d2.utils.events]: \u001b[0m eta: 0:14:53  iter: 1039  total_loss: 1.102  loss_cls: 0.4261  loss_box_reg: 0.37  loss_mask: 0.1901  loss_rpn_cls: 0.03271  loss_rpn_loc: 0.06559    time: 0.4788  last_time: 0.5256  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:46:16 d2.utils.events]: \u001b[0m eta: 0:14:44  iter: 1059  total_loss: 1.037  loss_cls: 0.4105  loss_box_reg: 0.313  loss_mask: 0.2318  loss_rpn_cls: 0.04909  loss_rpn_loc: 0.07682    time: 0.4790  last_time: 0.5775  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:46:26 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 1079  total_loss: 1.053  loss_cls: 0.3266  loss_box_reg: 0.3394  loss_mask: 0.2033  loss_rpn_cls: 0.03017  loss_rpn_loc: 0.1188    time: 0.4797  last_time: 0.4716  data_time: 0.0013  last_data_time: 0.0019   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:46:36 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 1099  total_loss: 0.9993  loss_cls: 0.3144  loss_box_reg: 0.3685  loss_mask: 0.2262  loss_rpn_cls: 0.03395  loss_rpn_loc: 0.07034    time: 0.4800  last_time: 0.4115  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:46:45 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 1119  total_loss: 1.043  loss_cls: 0.3828  loss_box_reg: 0.3634  loss_mask: 0.2169  loss_rpn_cls: 0.03113  loss_rpn_loc: 0.08456    time: 0.4799  last_time: 0.4985  data_time: 0.0013  last_data_time: 0.0009   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:46:54 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 1139  total_loss: 0.9918  loss_cls: 0.3357  loss_box_reg: 0.3373  loss_mask: 0.1782  loss_rpn_cls: 0.03723  loss_rpn_loc: 0.06286    time: 0.4793  last_time: 0.3880  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:47:04 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 1159  total_loss: 1.007  loss_cls: 0.3488  loss_box_reg: 0.3091  loss_mask: 0.2045  loss_rpn_cls: 0.04427  loss_rpn_loc: 0.08303    time: 0.4795  last_time: 0.5465  data_time: 0.0011  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:47:14 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 1179  total_loss: 0.9964  loss_cls: 0.3199  loss_box_reg: 0.3373  loss_mask: 0.198  loss_rpn_cls: 0.02609  loss_rpn_loc: 0.06078    time: 0.4799  last_time: 0.6437  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:47:24 d2.utils.events]: \u001b[0m eta: 0:13:43  iter: 1199  total_loss: 0.9389  loss_cls: 0.2862  loss_box_reg: 0.3254  loss_mask: 0.1864  loss_rpn_cls: 0.02231  loss_rpn_loc: 0.07104    time: 0.4800  last_time: 0.4619  data_time: 0.0011  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:47:33 d2.utils.events]: \u001b[0m eta: 0:13:34  iter: 1219  total_loss: 0.9281  loss_cls: 0.2449  loss_box_reg: 0.3583  loss_mask: 0.2125  loss_rpn_cls: 0.03359  loss_rpn_loc: 0.08643    time: 0.4801  last_time: 0.4491  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:47:44 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 1239  total_loss: 0.9828  loss_cls: 0.3248  loss_box_reg: 0.3131  loss_mask: 0.1728  loss_rpn_cls: 0.0314  loss_rpn_loc: 0.07613    time: 0.4805  last_time: 0.5525  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:47:53 d2.utils.events]: \u001b[0m eta: 0:13:19  iter: 1259  total_loss: 1.039  loss_cls: 0.32  loss_box_reg: 0.4162  loss_mask: 0.2198  loss_rpn_cls: 0.0437  loss_rpn_loc: 0.07727    time: 0.4804  last_time: 0.4442  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:48:02 d2.utils.events]: \u001b[0m eta: 0:13:08  iter: 1279  total_loss: 0.9129  loss_cls: 0.27  loss_box_reg: 0.3208  loss_mask: 0.1979  loss_rpn_cls: 0.03655  loss_rpn_loc: 0.07358    time: 0.4802  last_time: 0.4735  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:48:12 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 1299  total_loss: 0.9422  loss_cls: 0.3082  loss_box_reg: 0.3475  loss_mask: 0.2077  loss_rpn_cls: 0.03448  loss_rpn_loc: 0.0737    time: 0.4803  last_time: 0.4512  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:48:22 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 1319  total_loss: 0.8959  loss_cls: 0.2521  loss_box_reg: 0.3042  loss_mask: 0.1805  loss_rpn_cls: 0.03521  loss_rpn_loc: 0.05852    time: 0.4804  last_time: 0.4554  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:48:32 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 1339  total_loss: 0.8812  loss_cls: 0.2219  loss_box_reg: 0.3065  loss_mask: 0.2067  loss_rpn_cls: 0.02311  loss_rpn_loc: 0.09668    time: 0.4808  last_time: 0.6270  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:48:42 d2.utils.events]: \u001b[0m eta: 0:12:36  iter: 1359  total_loss: 0.9572  loss_cls: 0.2529  loss_box_reg: 0.3409  loss_mask: 0.1986  loss_rpn_cls: 0.02763  loss_rpn_loc: 0.0864    time: 0.4813  last_time: 0.4797  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:48:52 d2.utils.events]: \u001b[0m eta: 0:12:27  iter: 1379  total_loss: 0.9389  loss_cls: 0.2898  loss_box_reg: 0.3625  loss_mask: 0.2027  loss_rpn_cls: 0.02137  loss_rpn_loc: 0.05651    time: 0.4814  last_time: 0.6262  data_time: 0.0011  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:49:02 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 1399  total_loss: 0.8454  loss_cls: 0.31  loss_box_reg: 0.2834  loss_mask: 0.1625  loss_rpn_cls: 0.01885  loss_rpn_loc: 0.06885    time: 0.4816  last_time: 0.4853  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:49:11 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 1419  total_loss: 0.8122  loss_cls: 0.2256  loss_box_reg: 0.2681  loss_mask: 0.1623  loss_rpn_cls: 0.0305  loss_rpn_loc: 0.07131    time: 0.4812  last_time: 0.4083  data_time: 0.0012  last_data_time: 0.0015   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:49:21 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 1439  total_loss: 0.8866  loss_cls: 0.2954  loss_box_reg: 0.2829  loss_mask: 0.1583  loss_rpn_cls: 0.02366  loss_rpn_loc: 0.07662    time: 0.4811  last_time: 0.5142  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:49:30 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 1459  total_loss: 1.034  loss_cls: 0.3053  loss_box_reg: 0.3542  loss_mask: 0.2111  loss_rpn_cls: 0.03349  loss_rpn_loc: 0.09112    time: 0.4809  last_time: 0.6431  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:49:39 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 1479  total_loss: 1.021  loss_cls: 0.2967  loss_box_reg: 0.2958  loss_mask: 0.1957  loss_rpn_cls: 0.03412  loss_rpn_loc: 0.08758    time: 0.4805  last_time: 0.4543  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:49:49 d2.utils.events]: \u001b[0m eta: 0:11:30  iter: 1499  total_loss: 0.92  loss_cls: 0.3119  loss_box_reg: 0.282  loss_mask: 0.1646  loss_rpn_cls: 0.03547  loss_rpn_loc: 0.08146    time: 0.4804  last_time: 0.4622  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:49:59 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 1519  total_loss: 0.9005  loss_cls: 0.3067  loss_box_reg: 0.2988  loss_mask: 0.1912  loss_rpn_cls: 0.02174  loss_rpn_loc: 0.06777    time: 0.4807  last_time: 0.5982  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:50:08 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 1539  total_loss: 1.067  loss_cls: 0.329  loss_box_reg: 0.3718  loss_mask: 0.239  loss_rpn_cls: 0.04899  loss_rpn_loc: 0.07526    time: 0.4808  last_time: 0.4327  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:50:19 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 1559  total_loss: 0.8534  loss_cls: 0.2211  loss_box_reg: 0.3289  loss_mask: 0.1892  loss_rpn_cls: 0.02189  loss_rpn_loc: 0.09039    time: 0.4813  last_time: 0.4194  data_time: 0.0011  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:50:29 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 1579  total_loss: 0.7849  loss_cls: 0.2437  loss_box_reg: 0.2568  loss_mask: 0.1435  loss_rpn_cls: 0.02613  loss_rpn_loc: 0.07989    time: 0.4814  last_time: 0.4550  data_time: 0.0011  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:50:38 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 1599  total_loss: 0.8157  loss_cls: 0.2603  loss_box_reg: 0.2988  loss_mask: 0.1616  loss_rpn_cls: 0.02361  loss_rpn_loc: 0.07607    time: 0.4812  last_time: 0.5555  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:50:48 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 1619  total_loss: 0.748  loss_cls: 0.2013  loss_box_reg: 0.2342  loss_mask: 0.1458  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.06015    time: 0.4814  last_time: 0.5822  data_time: 0.0011  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:50:58 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 1639  total_loss: 0.9212  loss_cls: 0.306  loss_box_reg: 0.3123  loss_mask: 0.1737  loss_rpn_cls: 0.04938  loss_rpn_loc: 0.08387    time: 0.4819  last_time: 0.4145  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:51:08 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 1659  total_loss: 0.9527  loss_cls: 0.3024  loss_box_reg: 0.3331  loss_mask: 0.1867  loss_rpn_cls: 0.04815  loss_rpn_loc: 0.06838    time: 0.4821  last_time: 0.4779  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:51:19 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 1679  total_loss: 0.9142  loss_cls: 0.3491  loss_box_reg: 0.2586  loss_mask: 0.1976  loss_rpn_cls: 0.03538  loss_rpn_loc: 0.07614    time: 0.4825  last_time: 0.4266  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:51:29 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 1699  total_loss: 0.8548  loss_cls: 0.2523  loss_box_reg: 0.2751  loss_mask: 0.1853  loss_rpn_cls: 0.02678  loss_rpn_loc: 0.07707    time: 0.4827  last_time: 0.4397  data_time: 0.0014  last_data_time: 0.0013   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:51:38 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 1719  total_loss: 0.9175  loss_cls: 0.3026  loss_box_reg: 0.3134  loss_mask: 0.1875  loss_rpn_cls: 0.02655  loss_rpn_loc: 0.06946    time: 0.4827  last_time: 0.4575  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:51:48 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 1739  total_loss: 1.107  loss_cls: 0.3161  loss_box_reg: 0.3653  loss_mask: 0.2059  loss_rpn_cls: 0.04093  loss_rpn_loc: 0.08401    time: 0.4828  last_time: 0.4878  data_time: 0.0014  last_data_time: 0.0009   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:51:58 d2.utils.events]: \u001b[0m eta: 0:09:32  iter: 1759  total_loss: 0.9045  loss_cls: 0.2758  loss_box_reg: 0.2983  loss_mask: 0.1792  loss_rpn_cls: 0.02879  loss_rpn_loc: 0.07812    time: 0.4828  last_time: 0.4528  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:52:08 d2.utils.events]: \u001b[0m eta: 0:09:24  iter: 1779  total_loss: 0.9584  loss_cls: 0.1901  loss_box_reg: 0.3563  loss_mask: 0.1958  loss_rpn_cls: 0.03305  loss_rpn_loc: 0.07073    time: 0.4831  last_time: 0.4413  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:52:18 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 1799  total_loss: 0.8795  loss_cls: 0.2685  loss_box_reg: 0.3074  loss_mask: 0.1996  loss_rpn_cls: 0.02501  loss_rpn_loc: 0.06389    time: 0.4831  last_time: 0.5087  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:52:27 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 1819  total_loss: 0.8122  loss_cls: 0.2257  loss_box_reg: 0.2636  loss_mask: 0.2177  loss_rpn_cls: 0.02262  loss_rpn_loc: 0.07401    time: 0.4832  last_time: 0.5670  data_time: 0.0011  last_data_time: 0.0009   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:52:37 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 1839  total_loss: 0.9481  loss_cls: 0.2626  loss_box_reg: 0.3092  loss_mask: 0.1951  loss_rpn_cls: 0.03  loss_rpn_loc: 0.09443    time: 0.4832  last_time: 0.4402  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:52:46 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 1859  total_loss: 0.728  loss_cls: 0.1399  loss_box_reg: 0.2403  loss_mask: 0.1891  loss_rpn_cls: 0.0234  loss_rpn_loc: 0.07759    time: 0.4830  last_time: 0.4734  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:52:57 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 1879  total_loss: 0.7348  loss_cls: 0.2408  loss_box_reg: 0.2956  loss_mask: 0.1744  loss_rpn_cls: 0.02028  loss_rpn_loc: 0.06501    time: 0.4832  last_time: 0.4556  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:53:07 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 1899  total_loss: 0.884  loss_cls: 0.2345  loss_box_reg: 0.2998  loss_mask: 0.2219  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.07833    time: 0.4836  last_time: 0.5826  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:53:17 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 1919  total_loss: 0.8271  loss_cls: 0.2276  loss_box_reg: 0.287  loss_mask: 0.1626  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.06387    time: 0.4836  last_time: 0.4577  data_time: 0.0011  last_data_time: 0.0013   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:53:26 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 1939  total_loss: 0.7982  loss_cls: 0.2326  loss_box_reg: 0.2434  loss_mask: 0.1632  loss_rpn_cls: 0.02064  loss_rpn_loc: 0.06706    time: 0.4836  last_time: 0.4443  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:53:37 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 1959  total_loss: 0.8463  loss_cls: 0.2741  loss_box_reg: 0.2763  loss_mask: 0.1572  loss_rpn_cls: 0.02708  loss_rpn_loc: 0.07623    time: 0.4839  last_time: 0.6173  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:53:46 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 1979  total_loss: 1.008  loss_cls: 0.2946  loss_box_reg: 0.3055  loss_mask: 0.2126  loss_rpn_cls: 0.02955  loss_rpn_loc: 0.0733    time: 0.4839  last_time: 0.4609  data_time: 0.0013  last_data_time: 0.0016   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:53:56 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 1999  total_loss: 0.7671  loss_cls: 0.1949  loss_box_reg: 0.2661  loss_mask: 0.1631  loss_rpn_cls: 0.02079  loss_rpn_loc: 0.05607    time: 0.4840  last_time: 0.4619  data_time: 0.0014  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:54:06 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 2019  total_loss: 0.7759  loss_cls: 0.2024  loss_box_reg: 0.2946  loss_mask: 0.1891  loss_rpn_cls: 0.02278  loss_rpn_loc: 0.07308    time: 0.4840  last_time: 0.5778  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:54:15 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 2039  total_loss: 0.788  loss_cls: 0.222  loss_box_reg: 0.2885  loss_mask: 0.1656  loss_rpn_cls: 0.0242  loss_rpn_loc: 0.07465    time: 0.4838  last_time: 0.4655  data_time: 0.0014  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:54:25 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 2059  total_loss: 0.7503  loss_cls: 0.1861  loss_box_reg: 0.2686  loss_mask: 0.1675  loss_rpn_cls: 0.02616  loss_rpn_loc: 0.05931    time: 0.4837  last_time: 0.4691  data_time: 0.0014  last_data_time: 0.0025   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:54:35 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 2079  total_loss: 0.9435  loss_cls: 0.22  loss_box_reg: 0.341  loss_mask: 0.2257  loss_rpn_cls: 0.02064  loss_rpn_loc: 0.06523    time: 0.4841  last_time: 0.5832  data_time: 0.0013  last_data_time: 0.0009   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:54:44 d2.utils.events]: \u001b[0m eta: 0:06:58  iter: 2099  total_loss: 0.8151  loss_cls: 0.2194  loss_box_reg: 0.3298  loss_mask: 0.2234  loss_rpn_cls: 0.02252  loss_rpn_loc: 0.06849    time: 0.4839  last_time: 0.4316  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:54:54 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 2119  total_loss: 0.8851  loss_cls: 0.2177  loss_box_reg: 0.3442  loss_mask: 0.2143  loss_rpn_cls: 0.03057  loss_rpn_loc: 0.08157    time: 0.4838  last_time: 0.4953  data_time: 0.0011  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:55:04 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 2139  total_loss: 0.6807  loss_cls: 0.1922  loss_box_reg: 0.2431  loss_mask: 0.1693  loss_rpn_cls: 0.02404  loss_rpn_loc: 0.06953    time: 0.4839  last_time: 0.4631  data_time: 0.0011  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:55:13 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 2159  total_loss: 0.921  loss_cls: 0.2512  loss_box_reg: 0.3039  loss_mask: 0.1967  loss_rpn_cls: 0.02125  loss_rpn_loc: 0.09298    time: 0.4838  last_time: 0.5797  data_time: 0.0011  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:55:23 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 2179  total_loss: 0.7198  loss_cls: 0.1847  loss_box_reg: 0.2501  loss_mask: 0.1737  loss_rpn_cls: 0.03281  loss_rpn_loc: 0.07102    time: 0.4840  last_time: 0.4308  data_time: 0.0011  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:55:32 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 2199  total_loss: 0.8343  loss_cls: 0.2295  loss_box_reg: 0.2884  loss_mask: 0.1789  loss_rpn_cls: 0.03243  loss_rpn_loc: 0.06485    time: 0.4837  last_time: 0.4196  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:55:42 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 2219  total_loss: 0.8801  loss_cls: 0.2135  loss_box_reg: 0.321  loss_mask: 0.2036  loss_rpn_cls: 0.04066  loss_rpn_loc: 0.07422    time: 0.4838  last_time: 0.4093  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:55:52 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 2239  total_loss: 0.7932  loss_cls: 0.2076  loss_box_reg: 0.2673  loss_mask: 0.1577  loss_rpn_cls: 0.02513  loss_rpn_loc: 0.07901    time: 0.4837  last_time: 0.4201  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:56:02 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 2259  total_loss: 0.7652  loss_cls: 0.2276  loss_box_reg: 0.2538  loss_mask: 0.1675  loss_rpn_cls: 0.02203  loss_rpn_loc: 0.07144    time: 0.4838  last_time: 0.4331  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:56:11 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 2279  total_loss: 0.7104  loss_cls: 0.1779  loss_box_reg: 0.2447  loss_mask: 0.1676  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.05387    time: 0.4839  last_time: 0.5415  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:56:21 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 2299  total_loss: 0.7875  loss_cls: 0.1851  loss_box_reg: 0.2554  loss_mask: 0.1996  loss_rpn_cls: 0.02317  loss_rpn_loc: 0.08856    time: 0.4837  last_time: 0.5773  data_time: 0.0013  last_data_time: 0.0009   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:56:31 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 2319  total_loss: 0.7619  loss_cls: 0.2594  loss_box_reg: 0.2737  loss_mask: 0.173  loss_rpn_cls: 0.0185  loss_rpn_loc: 0.07132    time: 0.4839  last_time: 0.4837  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:56:41 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 2339  total_loss: 0.7949  loss_cls: 0.222  loss_box_reg: 0.2623  loss_mask: 0.1819  loss_rpn_cls: 0.02661  loss_rpn_loc: 0.09719    time: 0.4841  last_time: 0.5891  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:56:50 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 2359  total_loss: 0.7622  loss_cls: 0.2162  loss_box_reg: 0.265  loss_mask: 0.1859  loss_rpn_cls: 0.02046  loss_rpn_loc: 0.06606    time: 0.4839  last_time: 0.4702  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:57:00 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 2379  total_loss: 0.6371  loss_cls: 0.2021  loss_box_reg: 0.2602  loss_mask: 0.1477  loss_rpn_cls: 0.01516  loss_rpn_loc: 0.06352    time: 0.4840  last_time: 0.4616  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:57:10 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 2399  total_loss: 0.7838  loss_cls: 0.157  loss_box_reg: 0.2927  loss_mask: 0.1747  loss_rpn_cls: 0.016  loss_rpn_loc: 0.07262    time: 0.4839  last_time: 0.4512  data_time: 0.0013  last_data_time: 0.0019   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:57:19 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 2419  total_loss: 0.6437  loss_cls: 0.1511  loss_box_reg: 0.2218  loss_mask: 0.1736  loss_rpn_cls: 0.02249  loss_rpn_loc: 0.08982    time: 0.4839  last_time: 0.4470  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:57:29 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 2439  total_loss: 0.7792  loss_cls: 0.135  loss_box_reg: 0.2885  loss_mask: 0.2052  loss_rpn_cls: 0.01951  loss_rpn_loc: 0.07472    time: 0.4839  last_time: 0.5890  data_time: 0.0014  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:57:39 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 2459  total_loss: 0.5956  loss_cls: 0.126  loss_box_reg: 0.219  loss_mask: 0.153  loss_rpn_cls: 0.01937  loss_rpn_loc: 0.07256    time: 0.4840  last_time: 0.4685  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:57:49 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 2479  total_loss: 0.8187  loss_cls: 0.2068  loss_box_reg: 0.2964  loss_mask: 0.1764  loss_rpn_cls: 0.02181  loss_rpn_loc: 0.0853    time: 0.4841  last_time: 0.5706  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:57:59 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 2499  total_loss: 0.6898  loss_cls: 0.1793  loss_box_reg: 0.2763  loss_mask: 0.1489  loss_rpn_cls: 0.01944  loss_rpn_loc: 0.04866    time: 0.4842  last_time: 0.4681  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:58:09 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 2519  total_loss: 0.7929  loss_cls: 0.2115  loss_box_reg: 0.2853  loss_mask: 0.1977  loss_rpn_cls: 0.02009  loss_rpn_loc: 0.08263    time: 0.4844  last_time: 0.3939  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:58:19 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 2539  total_loss: 0.9016  loss_cls: 0.2207  loss_box_reg: 0.2824  loss_mask: 0.2049  loss_rpn_cls: 0.01234  loss_rpn_loc: 0.09942    time: 0.4846  last_time: 0.4495  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:58:29 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 2559  total_loss: 0.7234  loss_cls: 0.2176  loss_box_reg: 0.253  loss_mask: 0.1645  loss_rpn_cls: 0.02804  loss_rpn_loc: 0.08026    time: 0.4845  last_time: 0.3926  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:58:39 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 2579  total_loss: 0.7541  loss_cls: 0.1496  loss_box_reg: 0.2729  loss_mask: 0.1803  loss_rpn_cls: 0.01856  loss_rpn_loc: 0.06388    time: 0.4848  last_time: 0.5488  data_time: 0.0011  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:58:49 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 2599  total_loss: 0.6987  loss_cls: 0.1586  loss_box_reg: 0.2065  loss_mask: 0.1669  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.07739    time: 0.4847  last_time: 0.4840  data_time: 0.0011  last_data_time: 0.0013   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:58:58 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 2619  total_loss: 0.7905  loss_cls: 0.1858  loss_box_reg: 0.2725  loss_mask: 0.1968  loss_rpn_cls: 0.01332  loss_rpn_loc: 0.0676    time: 0.4846  last_time: 0.4651  data_time: 0.0013  last_data_time: 0.0009   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:59:08 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 2639  total_loss: 0.8536  loss_cls: 0.2248  loss_box_reg: 0.2622  loss_mask: 0.1542  loss_rpn_cls: 0.03158  loss_rpn_loc: 0.06883    time: 0.4847  last_time: 0.4421  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:59:18 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 2659  total_loss: 0.7862  loss_cls: 0.2283  loss_box_reg: 0.2961  loss_mask: 0.1831  loss_rpn_cls: 0.01938  loss_rpn_loc: 0.06811    time: 0.4847  last_time: 0.5793  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:59:28 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 2679  total_loss: 0.9152  loss_cls: 0.2478  loss_box_reg: 0.3001  loss_mask: 0.1941  loss_rpn_cls: 0.03204  loss_rpn_loc: 0.08027    time: 0.4849  last_time: 0.5962  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:59:38 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 2699  total_loss: 0.7162  loss_cls: 0.2047  loss_box_reg: 0.2463  loss_mask: 0.1619  loss_rpn_cls: 0.02893  loss_rpn_loc: 0.06753    time: 0.4849  last_time: 0.4345  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:59:48 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 2719  total_loss: 0.7201  loss_cls: 0.1563  loss_box_reg: 0.2545  loss_mask: 0.1759  loss_rpn_cls: 0.01368  loss_rpn_loc: 0.05532    time: 0.4850  last_time: 0.4589  data_time: 0.0013  last_data_time: 0.0009   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 10:59:58 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 2739  total_loss: 0.8013  loss_cls: 0.1919  loss_box_reg: 0.2611  loss_mask: 0.174  loss_rpn_cls: 0.02637  loss_rpn_loc: 0.08173    time: 0.4851  last_time: 0.5812  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:00:08 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 2759  total_loss: 0.6313  loss_cls: 0.1532  loss_box_reg: 0.2104  loss_mask: 0.1592  loss_rpn_cls: 0.01803  loss_rpn_loc: 0.07651    time: 0.4854  last_time: 0.5679  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:00:19 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 2779  total_loss: 0.7264  loss_cls: 0.1557  loss_box_reg: 0.2571  loss_mask: 0.1556  loss_rpn_cls: 0.01656  loss_rpn_loc: 0.07732    time: 0.4857  last_time: 0.4718  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:00:29 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 2799  total_loss: 0.8112  loss_cls: 0.1692  loss_box_reg: 0.3045  loss_mask: 0.211  loss_rpn_cls: 0.0224  loss_rpn_loc: 0.05914    time: 0.4858  last_time: 0.6050  data_time: 0.0014  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:00:39 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 2819  total_loss: 0.7182  loss_cls: 0.124  loss_box_reg: 0.2694  loss_mask: 0.2043  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.06126    time: 0.4860  last_time: 0.5728  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:00:49 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 2839  total_loss: 0.7959  loss_cls: 0.1781  loss_box_reg: 0.2526  loss_mask: 0.1815  loss_rpn_cls: 0.02262  loss_rpn_loc: 0.08447    time: 0.4861  last_time: 0.4347  data_time: 0.0011  last_data_time: 0.0013   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:00:59 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 2859  total_loss: 0.743  loss_cls: 0.2222  loss_box_reg: 0.2686  loss_mask: 0.1663  loss_rpn_cls: 0.02639  loss_rpn_loc: 0.06403    time: 0.4862  last_time: 0.5688  data_time: 0.0012  last_data_time: 0.0014   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:01:09 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 2879  total_loss: 0.7143  loss_cls: 0.1922  loss_box_reg: 0.226  loss_mask: 0.1629  loss_rpn_cls: 0.02386  loss_rpn_loc: 0.06394    time: 0.4862  last_time: 0.3923  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:01:18 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 2899  total_loss: 0.8216  loss_cls: 0.1679  loss_box_reg: 0.2828  loss_mask: 0.1922  loss_rpn_cls: 0.02139  loss_rpn_loc: 0.08175    time: 0.4862  last_time: 0.6025  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:01:28 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 2919  total_loss: 0.6353  loss_cls: 0.1878  loss_box_reg: 0.2446  loss_mask: 0.1319  loss_rpn_cls: 0.02446  loss_rpn_loc: 0.05641    time: 0.4863  last_time: 0.5090  data_time: 0.0012  last_data_time: 0.0016   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:01:38 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 2939  total_loss: 0.8293  loss_cls: 0.2391  loss_box_reg: 0.2813  loss_mask: 0.2023  loss_rpn_cls: 0.01609  loss_rpn_loc: 0.08295    time: 0.4863  last_time: 0.6211  data_time: 0.0016  last_data_time: 0.0013   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:01:49 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 2959  total_loss: 0.7735  loss_cls: 0.2044  loss_box_reg: 0.2692  loss_mask: 0.1688  loss_rpn_cls: 0.0124  loss_rpn_loc: 0.06373    time: 0.4866  last_time: 0.4766  data_time: 0.0016  last_data_time: 0.0023   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:01:58 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 2979  total_loss: 0.6139  loss_cls: 0.148  loss_box_reg: 0.2171  loss_mask: 0.1659  loss_rpn_cls: 0.01593  loss_rpn_loc: 0.07119    time: 0.4865  last_time: 0.5556  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:02:17 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2999  total_loss: 0.6841  loss_cls: 0.1402  loss_box_reg: 0.2347  loss_mask: 0.1756  loss_rpn_cls: 0.01875  loss_rpn_loc: 0.07538    time: 0.4866  last_time: 0.4328  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025  max_mem: 4112M\n",
      "\u001b[32m[05/14 11:02:17 d2.engine.hooks]: \u001b[0mOverall training speed: 2998 iterations in 0:24:18 (0.4866 s / it)\n",
      "\u001b[32m[05/14 11:02:17 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:29 (0:00:10 on hooks)\n",
      "\u001b[32m[05/14 11:02:17 d2.data.datasets.coco]: \u001b[0mLoaded 300 images in COCO format from dataset/annotation/valid_annotations.json\n",
      "\u001b[32m[05/14 11:02:17 d2.data.build]: \u001b[0mDistribution of instances among all 15 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| Whole Chicken | 22           | Chicken Bre.. | 50           | Chicken Wings | 125          |\n",
      "|  Chicken Leg  | 92           | Chicken Thigh | 104          |      Egg      | 80           |\n",
      "|     Tofu      | 45           |   Lean Pork   | 58           |   Lean Beef   | 21           |\n",
      "| Sweet Potato  | 74           |   Potatoes    | 26           |     Rice      | 22           |\n",
      "| Whole Wheat.. | 50           |  White Bread  | 59           |   Broccoli    | 38           |\n",
      "|               |              |               |              |               |              |\n",
      "|     total     | 866          |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[05/14 11:02:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[05/14 11:02:17 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[05/14 11:02:17 d2.data.common]: \u001b[0mSerializing 300 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/14 11:02:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/14 11:02:17 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03190454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/14 11:03:39 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[05/14 11:03:39 d2.data.datasets.coco]: \u001b[0mLoaded 300 images in COCO format from dataset/annotation/valid_annotations.json\n",
      "\u001b[32m[05/14 11:03:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[05/14 11:03:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[05/14 11:03:39 d2.data.common]: \u001b[0mSerializing 300 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/14 11:03:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[32m[05/14 11:03:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 batches\n",
      "\u001b[32m[05/14 11:03:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. Dataloading: 0.0007 s/iter. Inference: 0.1341 s/iter. Eval: 0.0107 s/iter. Total: 0.1455 s/iter. ETA=0:00:42\n",
      "\u001b[32m[05/14 11:03:54 d2.evaluation.evaluator]: \u001b[0mInference done 46/300. Dataloading: 0.0008 s/iter. Inference: 0.1236 s/iter. Eval: 0.0192 s/iter. Total: 0.1437 s/iter. ETA=0:00:36\n",
      "\u001b[32m[05/14 11:03:59 d2.evaluation.evaluator]: \u001b[0mInference done 78/300. Dataloading: 0.0007 s/iter. Inference: 0.1236 s/iter. Eval: 0.0262 s/iter. Total: 0.1506 s/iter. ETA=0:00:33\n",
      "\u001b[32m[05/14 11:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 110/300. Dataloading: 0.0007 s/iter. Inference: 0.1248 s/iter. Eval: 0.0276 s/iter. Total: 0.1531 s/iter. ETA=0:00:29\n",
      "\u001b[32m[05/14 11:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 147/300. Dataloading: 0.0007 s/iter. Inference: 0.1241 s/iter. Eval: 0.0246 s/iter. Total: 0.1495 s/iter. ETA=0:00:22\n",
      "\u001b[32m[05/14 11:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 182/300. Dataloading: 0.0007 s/iter. Inference: 0.1236 s/iter. Eval: 0.0242 s/iter. Total: 0.1485 s/iter. ETA=0:00:17\n",
      "\u001b[32m[05/14 11:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 215/300. Dataloading: 0.0007 s/iter. Inference: 0.1258 s/iter. Eval: 0.0227 s/iter. Total: 0.1493 s/iter. ETA=0:00:12\n",
      "\u001b[32m[05/14 11:04:24 d2.evaluation.evaluator]: \u001b[0mInference done 248/300. Dataloading: 0.0007 s/iter. Inference: 0.1259 s/iter. Eval: 0.0234 s/iter. Total: 0.1501 s/iter. ETA=0:00:07\n",
      "\u001b[32m[05/14 11:04:29 d2.evaluation.evaluator]: \u001b[0mInference done 282/300. Dataloading: 0.0007 s/iter. Inference: 0.1260 s/iter. Eval: 0.0232 s/iter. Total: 0.1501 s/iter. ETA=0:00:02\n",
      "\u001b[32m[05/14 11:04:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.582462 (0.154517 s / iter per device, on 1 devices)\n",
      "\u001b[32m[05/14 11:04:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.125298 s / iter per device, on 1 devices)\n",
      "\u001b[32m[05/14 11:04:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[05/14 11:04:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_R50_DC5\\coco_instances_results.json\n",
      "\u001b[32m[05/14 11:04:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[05/14 11:04:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[05/14 11:04:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.42 seconds.\n",
      "\u001b[32m[05/14 11:04:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[05/14 11:04:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.642\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.457\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.421\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.619\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654\n",
      "\u001b[32m[05/14 11:04:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 40.708 | 64.228 | 45.655 |  nan  | 27.438 | 42.136 |\n",
      "\u001b[32m[05/14 11:04:34 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[05/14 11:04:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category          | AP     | category       | AP     | category      | AP     |\n",
      "|:------------------|:-------|:---------------|:-------|:--------------|:-------|\n",
      "| Whole Chicken     | 39.895 | Chicken Breast | 32.048 | Chicken Wings | 18.694 |\n",
      "| Chicken Leg       | 33.130 | Chicken Thigh  | 37.330 | Egg           | 41.339 |\n",
      "| Tofu              | 20.290 | Lean Pork      | 32.450 | Lean Beef     | 53.483 |\n",
      "| Sweet Potato      | 46.345 | Potatoes       | 49.595 | Rice          | 74.999 |\n",
      "| Whole Wheat Bread | 43.555 | White Bread    | 38.989 | Broccoli      | 48.472 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[05/14 11:04:34 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[05/14 11:04:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[05/14 11:04:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[05/14 11:04:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.612\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.449\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.626\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646\n",
      "\u001b[32m[05/14 11:04:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 39.862 | 61.160 | 44.925 |  nan  | 15.933 | 41.854 |\n",
      "\u001b[32m[05/14 11:04:34 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[05/14 11:04:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category          | AP     | category       | AP     | category      | AP     |\n",
      "|:------------------|:-------|:---------------|:-------|:--------------|:-------|\n",
      "| Whole Chicken     | 38.532 | Chicken Breast | 34.219 | Chicken Wings | 13.267 |\n",
      "| Chicken Leg       | 29.760 | Chicken Thigh  | 39.455 | Egg           | 44.475 |\n",
      "| Tofu              | 22.099 | Lean Pork      | 30.581 | Lean Beef     | 57.357 |\n",
      "| Sweet Potato      | 42.467 | Potatoes       | 48.269 | Rice          | 80.501 |\n",
      "| Whole Wheat Bread | 37.079 | White Bread    | 36.672 | Broccoli      | 43.202 |\n",
      "OrderedDict({'bbox': {'AP': 40.707631040892664, 'AP50': 64.22838383725549, 'AP75': 45.655344666306746, 'APs': nan, 'APm': 27.438073730676223, 'APl': 42.135501273357626, 'AP-Whole Chicken': 39.89480278233803, 'AP-Chicken Breast': 32.0480572325433, 'AP-Chicken Wings': 18.6941517369958, 'AP-Chicken Leg': 33.13044694642393, 'AP-Chicken Thigh': 37.330457202668654, 'AP-Egg': 41.33937837000419, 'AP-Tofu': 20.28987971245409, 'AP-Lean Pork': 32.449940980764694, 'AP-Lean Beef': 53.48302009144336, 'AP-Sweet Potato': 46.345055801863616, 'AP-Potatoes': 49.595191251684746, 'AP-Rice': 74.9988213107025, 'AP-Whole Wheat Bread': 43.55497330307903, 'AP-White Bread': 38.98874448410328, 'AP-Broccoli': 48.47154440632056}, 'segm': {'AP': 39.862347076244, 'AP50': 61.16039961960015, 'AP75': 44.92548318996163, 'APs': nan, 'APm': 15.933003832642617, 'APl': 41.85380058605734, 'AP-Whole Chicken': 38.53210393999543, 'AP-Chicken Breast': 34.21923811872692, 'AP-Chicken Wings': 13.26680023804866, 'AP-Chicken Leg': 29.759559799657175, 'AP-Chicken Thigh': 39.454671559985584, 'AP-Egg': 44.475098326332315, 'AP-Tofu': 22.099309824337375, 'AP-Lean Pork': 30.581210414839568, 'AP-Lean Beef': 57.357256198591514, 'AP-Sweet Potato': 42.46704799946893, 'AP-Potatoes': 48.268971141860725, 'AP-Rice': 80.500942951438, 'AP-Whole Wheat Bread': 37.07912291937162, 'AP-White Bread': 36.67190645114305, 'AP-Broccoli': 43.20196625986312}})\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "evaluator = COCOEvaluator(\"food_val\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "val_loader = build_detection_test_loader(cfg, \"food_val\")\n",
    "print(inference_on_dataset(trainer.model, val_loader, evaluator))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foodenv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
